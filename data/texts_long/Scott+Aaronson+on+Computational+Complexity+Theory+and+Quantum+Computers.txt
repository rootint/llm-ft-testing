 Today we have Scott Aronson, a UT professor, CS, and also a blogger at Settle Optimized. And on the top of your blog, you have something that says, if you take just one piece of information away from this blog, quantum computers would not solve hard search problems instantaneously by simply trying all the possible solutions at once. Why not? Great question.'d you ask uh so uh uh so yeah so i've been uh you know uh researching uh quantum computing uh working in this area for about 20 years i've been blogging about it for uh 15 years i guess and uh uh and uh you know the most single And the single most common misconception, which you find repeated in almost every popular article about the subject that is written, it says, well, a classical computer is made of bits, and so it can just try each possible solution one by one. But a quantum computer is made of qubits, which can be zero and one at the same time. And this means that if you have 100 qubits, that the quantum computer can explore two to the hundredth power state simultaneously. And then it can just try all the possible answers at once. Well, that is gesturing towards something in the vicinity of the truth, but it's also very seriously misleading. And it leads people to think that quantum computers would have capabilities that actually we don't think that they would have. And this is not even controversial within this field. We all know this, but it's very hard to get the message out. I've been trying. So here's the situation, right? The central thing that quantum mechanics says about the world is that to each possible state of a physical system, like each possible way that it could be when you measure it, you have to assign a number called an amplitude. And amplitudes are related to probabilities, right? A larger amplitude means you're more likely to see that outcome, okay? But amplitudes are different from probabilities. You know, unlike a probability, an amplitude can be negative, okay? In fact, it can even be a complex number. And so all the sort of magic of quantum mechanics, anything you've ever heard about the weirdness of the quantum world, you know, yeah, the spookiness, it all boils down in the end to the way that these amplitudes work differently from probabilities, right? In particular, probabilities can only sort work differently from probabilities, right? In particular, probabilities can only sort of add up positively, right? The more ways that something could happen, right, that just keeps increasing the probability that it happens, okay? But amplitudes can, as we say, interfere destructively and cancel each other out, right? So like if a photon could reach a certain point, for example, in one way with a positive amplitude and in another way with a negative amplitude, those two things can cancel so that you never see the photon there at all, as in the famous double slit experiment, right? If you won't take this on my authority, you know, you can take it on Richard Feynman's, right? That he used to say that, you know, everything in quantum mechanics boils down to these minus signs. Yeah, absolutely. So a quantum computer is just a device that could maintain a state that is, as we say, a superposition, right, with some amplitude for every possible configuration of the bits. So indeed, if you had a computer with 100 quantum bits, qubits as we call them, that is 2 to the 100th power amplitudes that are needed to maintain that computer state. And it's actually very easy to create, as we say, an equal superposition over all the possible states, easy to create, as we say, an equal superposition over all the possible states, right? Which you could think of as every possible key for a cryptographic code, every possible solution to your optimization problem, right? So that's what the popular articles are trying to talk about, right? All of that is true, okay? The problem is, well, for a computer to be useful, at some point, you've got to look at the thing, right? At some point you've got to measure and get an answer out, okay? And the rules of quantum mechanics are very specific about how these amplitudes turn into ordinary probabilities that you'll see something, right? And the rule is the probability of some outcome is just the squared absolute value of its amplitude. That's the rule, right? You know, it sounds a little technical, but that's one of the most basic rules of the universe. So it's probably, probably, you know. If you saw it on paper, it would be. Yeah, that's right. That's right. So, but in particular, one thing that means is that if I just created an equal superposition over all the possible answers to some problem, and then I measure it, not having done anything else, then all I'm going to see will be a random answer. Now, if all I wanted was a random answer, I could have just flipped a coin a few times, saved billions of dollars building this device. So the entire hope of getting a speed advantage from a quantum computer is to exploit the way that amplitudes work differently, right? It's to try to choreograph a pattern of interference where for each wrong answer to your computational problem, like some of the paths leading there have positive amplitude, some have negative amplitude, so they cancel each other out. Whereas for the right answer, you want all the contributions to it to reinforce each other, right? The tricky part is you've got to figure out how to do that despite not knowing in advance which answer is the right one. Right. In addition to the error correction. That's right. Oh, yeah, yeah. All of that, too. Yeah, of course. You know, correction that's right oh yeah yeah all of that too yeah of course you know those are all the engineering difficulties right now i'm talking about even if you had a perfect quantum computer right it's still not obvious how to get a speed advantage from it right because you gotta choreograph this interference pattern right it's like you know nature gives you this really bizarre hammer and it was not until the 1990s that people really started figuring out what nails you could hit with this hammer. Well, this is a question I had for you. So quantum computers seem to be in this technology category rather than the science category. So we did a podcast with Rana Adhikari from LIGO. And that is squarely put in the science category. How did quantum computers end up in this like business use case category? That's a super interesting question, right? Because, yeah, indeed, you know, often when magazines and newspapers are writing about quantum computing, they put a technology reporter on it, right? And then, you know, they want to know about, well, you know, how is this going to impact the finance industry in the next five years? And, you know, they will, let's just see if the universe, let's prove that the universe has this capability at all. How about we do that? It's an important understanding. Yeah, that's right. So I think that, I mean, part of what makes it exciting is that, you know, this is fundamental science, right? I mean, I mean, in the sense, I mean, not in the sense that we're overthrowing any of the known laws of physics. In fact, all we're doing is, in some sense, we're taking completely seriously quantum mechanics as it was written down in 1926. It hasn't changed at all since that time. But what we're doing, what we're trying to do, is to test it in an entirely new regime, right? Where really, it has never been tested in this regime of, let's say, universal quantum computation or quantum error correction. The math seems very unequivocal that this could be done, but this is really building something that has never been built before and so uh so i think you know and and there are uh skeptics i talk to them a lot they come on my blog you know uh uh often who say this will never work this is you know this is so absurd that you could build this quantum computer that you know there has to be some new law of physics that will prevent it but there seem to be some new law of physics that will prevent it but there seem to be equal amounts of like crackpot scientists who come on your blog and figure out like the pnp problem oh yeah no i get i get no i get every kind of you know of of original thinker on my blog i mean that's but um that's you know one of the joys and pitfalls of blogging, I guess, right? But, you know, in particular, you know, there are people, you know, including very serious and well-known computer scientists and physicists who say, well, look, you know, if not a new law of physics, like, it must be that we just don't understand quantum mechanics well enough, right? That, you know, the error is going to, you know, inherently kill you. You will not be able to scale this. You know, maybe you can build a small quantum computer, but, you know, nature will prevent you from scaling it up, right? And, you know, in the 90s, that actually seemed like a pretty plausible view, you know, even to many of the experts in this field, right? What changed everything for most of us in the 90s was the discovery of quantum error correction, well, if you want to build a scalable quantum computer, you don't need to get perfect qubits that are perfectly isolated from their environment, which of course would be a physical absurdity, right? You merely need to get them ridiculously well isolated from their environment and way better than we can do. we can do, but in the minds of most experts, it reduced it to merely a staggeringly hard engineering problem, right? Now, what I like to say is that if it turned out that there's some deep reason why this could never be done, and if the attempt to build quantum computers were to lead instead to the discovery of that new impossibility principle, well, then that's awesome, right? I mean, that's like Nobel Prizes for whoever discovers it. And that's, I mean, compared to that, the idea that you can build a quantum computer is like the more boring possibility. That's the more conservative option, right? But, you know, we're, as I said, we're testing quantum mechanics in this new regime, and we want to know the truth, whatever it is. So I think that there is fundamental science here. And to me, that's really why I got into this. I like to say, for me, the number one application of a quantum computer is not breaking cryptographic codes. It's not optimization problems. It's not simulating quantum physics. It's just proving the skeptics wrong. Just, you know. What happened in your childhood? A lot happened, but, you know, we don't have to go into that. I mean, but, no, I mean, you know, it is sort of seeing whether nature actually has this computational ability beneath the surface. But now, of course, what made a lot of the world interested in it is that it actually could have some applications, right? Maybe the most important application that we know about is just giving us this new way to simulate nature, simulate physics and chemistry, and maybe discover new drugs, discover new materials, right? You know, I mean, that's the application that Richard Feynman and the others had in mind when they first proposed the idea of quantum computing in the 1980s. But before we started recording, you were talking about what you've been working on for the past year, which is potentially relevant because, you know, many of these drug finding applications might need, say, a million qubits, right? We might already be able to start getting some of these with some hundreds of qubits. Okay. It's not, you know, people are going to try. But we're not even at 50 yet, right? That's right. Yeah. That's right. Not 50 that we have good enough control over, certainly. Right that we have good enough control over. What was the application that you were working on? I have a new idea that I've been working on for the past four months or so. There's been independent work by others pursuing related ideas. This, as far as I can see, may be the first application of quantum computing that people could actually be able to realize with like near term devices with 50 or 60 or 70 qubits. And this application is to generate cryptographically secure random bits. OK, so, for example, if you know you have these proof of stake cryptocurrencies, you need a huge public source of random bits to run this lottery to decide who is allowed to add a new block to the blockchain. For all sorts of other cryptographic applications, you need public random bits. Of course, decide which precincts to audit in an election, for example. Of course, for cryptography you also need secret random bits. Now, for secret random bits you would need to own the quantum computer yourself. You wouldn't want to download them over the internet. right? But so now, you know, there are many, you know, websites already that will give you public randomness. There's one called random.org where you can just get random bits to order. Allegedly random. Yeah, right. Yes, yes. Allegedly random. Thank you, right? NIST runs something called the Randomnessness beacon where every minute they release 512 new random bits to the world okay right which are partly you know generated using quantum mechanical processes right so now you know you could say if you believe quantum mechanics right there you know which you should then uh it's very easy to get random bits right randomness is going to baked baked into quantum mechanics, famously. You could just keep measuring some photons, measure the polarization, outcomes will be random. Or just get some radioactive material from Kim Jong or whatever. Just put a Geiger counter. The decays will be random. But if you were to get these random bits from the internet, right, then the question is, how do you know how they were generated? How do you know that the hardware wasn't backdoored by someone, right? In fact, you know, NIST did have a standard for pseudo random bits, which we learned a few years ago because of the Snowden documents was back doored, most likely by the NSA. So there is a big issue of how can you trust randomness? How can you prove to someone that bits were actually generated randomly? It seems almost like a philosophical impossibility. So how does this work? Yeah, okay. So there are ways to do this with quantum mechanics. Over the past 10 years, people discovered that one way to do it is using the Bell inequality, which means if you had like two entangled particles that were far away and you measure them and you see that they have a certain type of Correlation that you know could not have been produced classically, right? This is kind of the famous Bell inequality It's the thing that disproves Einstein that you know that there's no sort of secret local hidden variables that control what's going on, right? That sort of quantum entanglement is a real thing in the universe. But, you know, for many decades, people said, well, you know, this, you know, is conceptually, you know, a breakthrough that Bell made. Of course, it's completely useless, right? Of course, you know, you don't actually need to create these correlations between faraway particles, right? But, you know, what people realized a decade ago is actually the fact that you've created those correlation also means that there has to be some randomness in the bits that are produced, because the only way to create those correlations without using true randomness would be using communication. But if we put the things far enough away that a signal could not have gotten from one to the other, even traveling at the speed of light, then we can have some kind of assurance that, yeah, there is randomness there. But now the one thing is you've got to believe that these devices were really separated far enough, right? Which, again, if it's over the internet, you know, how would you know? So the new realization is that you can get guaranteed randomness with a single device, you know, at least under some cryptographic assumptions. Okay. As long as that single device is able to do quantum computations that are sort of hard to simulate with a classical computer so basically what you would do imagine that google let's say has some 70 qubit quantum computer as indeed they are working to build right now i just visited their lab a month ago you know they're they're working on it. I don't know when it's going to be ready. But then you could, you with your classical computer, right, could submit challenges to the quantum computer that basically say, just run this quantum circuit, which is, you know, pretty random looking, pretty, you know pretty messy, arbitrary quantum circuit. But just run this quantum circuit, and then it will lead to some probability distribution over output strings. In this case, strings of 70 bits. And so then just give me a sample from this distribution. And I'll just keep sending it challenges of that kind, one after another, and each time demand that it send me back the sample from this distribution in a very short time, like let's say half a second. And then I take these samples. And now if Google did the right thing, then these samples have lots of randomness in them. But the more interesting part is that under a cryptographic assumption, you know, if I can check that these samples were actually correlated with the distributions that they're supposed to be. So in other words, like one shows up 10% of the time. Well, yeah, like, you know, so all the outcomes are pretty unlikely, right? Because, you know, they're all like on the order of two to the minus 70 probability of occurring, but not exactly, right? Some of them are like twice two to the minus 70. Some are half two to the minus 70, right? And so I can check that the heavier outcomes are more likely to occur, right? I can do some statistical test to sort of check whether Google is plausibly sampling from this distribution, right? And then what we can do some statistical test to sort of check whether Google is plausibly sampling from this distribution. And then what we can do is we can mathematically prove that if you'll assume that some problem is hard for a quantum computer that looks like it should be hard, then it would follow that even with a quantum computer, the only way that Google could be quickly generating samples that pass this test is to generate them truly randomly, right? There's no secretly deterministic way to do it, you know, without them spending a huge amount of computational power more than we believe that they have. And so when you were testing this out, or did you test it out with tons of compute? It has not been tested out with real quantum computers yet. I mean, you know, it's so so the apparatus that I use is a pen, paper. And I did I did use a maple a little bit to do some numerical optimization. So, yeah, the sexiest thing. I'm a theoretical computer scientist. Yeah, okay. But Google is hoping to move forward and test this out and actually demonstrate it once they have the device, right? I mean, of course, it could also be simulated with a classical computer. One could code something up. But one thing that's exciting about this is that it looks like pretty much as soon as you have a 60 or 70 qubit quantum computer that can sample any distributions that are hard to sample with a classical computer, you can pretty much get this application, right? So it's sort of designed for near-term quantum computers. And in fact, even if you had many more qubits, we couldn't really make use of them for this application because the verification, if I have n qubits, is going to take two to the n time with my classical computer. Which means that with a thousand qubits, it might be working fine, and yet we could never verify it. Okay. Man, what other projects did you clear from the cache on your sabbatical? Well, not many. I know I came, so I was on sabbatical in Tel Aviv for a year. I came with a long list of old papers that needed to be written up. And I wrote up almost none of them. And instead, I just started new projects and put the old ones even further uh onto the back burner but you know which which is often the way it goes unfortunately but uh but but actually uh uh i did uh write a paper this year about a a new procedure for measuring quantum states which uh is called uh i call shadow tomography. I had a more boring name for it, and then a physicist trained me. I appreciate it. Yeah. You got punched up. Yeah, he came up. Physicists are much better than computer scientists at naming things. So it's called shadow tomography. And what it is, so measurement in quantum mechanics is an inherently destructive process, right? You know, famously, it collapses the wave function, it collapses your state, and you only get one chance, right? So the problem that shadow tomography is trying to solve is, let's say, you know, I have a small number of copies of a quantum state, but I want to know the behavior of that quantum state on a large number of measurements. So like a much much larger number of different measurements than the number of copies that I have. Maybe even an exponentially greater number. Let's say for simplicity that each measurement has just two possible outcomes. Yes or no. But I want to know for each measurement, what is approximately the probability that it would return yes, applied to this state. So of course, if I have enough copies, I could just measure each copy with a different measurement. But I don't have enough copies. And again, if I have enough copies, then I could just fully learn my state, measure each copy, and then eventually, by collecting enough statistics, I could write down in my classical computer a full description of the quantum state. But I don't have enough copies for that either. Where are these assumptions coming from, that you don't have enough copies? Oh, well, I'm telling you that because this makes the question interesting. All right, fair enough. I mean, you know, I mean, if we do have enough copies, then we do one of those simpler things. Right. Right? But I'm asking what happens if we don't. If we don't, all right. Right? So, you know, you have, you know, maybe it's a way to take these states and manipulate them very, very carefully so that you can keep reusing them over and over and learn the- Without destroying them. Without destroying them, right. Damaging them only slightly each time, right. And learn the answers to each of these yes or no questions, which again, there could be exponentially more of than there are copies of the state. How does the partial destruction work? Well, okay. So it has to do with, so it's the way that measurement works in quantum mechanics, right? Is that if you measure your state in the wrong basis, then the state is destroyed. So, for example, if I have an electron that's very spread out in position and I ask it what's its position, I now force it to make up its mind. right then i i now force it to make up its mind right it's localized now to one place and then that destroys all the other information that was in that superposition over positions on the other hand if i ask that electron for its momentum well then its momentum might have been much more determinate right and you know if i ask us if i ask a question we're given knowledge of the state and someone could have almost perfectly predicted the answer to that question, then the state only needs to be damaged slightly by the measurement. Right. OK. I mean, we know that not all measurements are destructive. You know, for example, you know, if I read a book, you know, and I see what words are written in it, my friend can read the book, too. Right. So that's a non-destructive measurement. Right. see what words are written in it. My friend can read the book too, right? So that's a non-destructive measurement, right? But even in the quantum realm, like if I'm careful to measure a state, like in a basis where it's already been localized, right, then that's not going to damage it by very much, right? So, you know, now the challenge, of course, is now I have these copies and I say, I don't know in which basis, you know, they are or aren't localized, right? But I can, you know, do something, you know, and this measurement procedure that I designed takes a very long time to carry out. So I'm not promising you that it's fast, right? But it makes very, very careful reuse of these same states over and over again. So, you know, so this had various implications. It solved various theoretical questions that I cared about. And by the way, I had conjectured that this was not possible, right? And so this is the way that research often happens for me. I tried to rule it out. I was unable to rule it out. And then eventually I figured out why, right? So was it just like brute force, pen and paper? Or did you have a conversation that sparked it? What happened? thought about it more. Of course, I was building on earlier work that I and others had done. You never start completely from scratch. You know the tools that were used to solve related problems. Anyway, this year, we've carried it further So I have a joint work with Guy Rothblum from the Weizmann Institute. And so what happened was I gave a talk about this work. And he said, this idea of measuring a quantum state very gently and not damaging it, this sounds a lot like what I work on. Guy is a classical computer scientist who works in a field called differential privacy. Some people may have heard of this. This is actually used, I think, in some... I don't know if Facebook uses it, but some websites use this. It's a way that you can do data mining for right, for like a database of like a whole bunch of users' sensitive data. You know, it could be their medical records, could be, you know, all their personal data. But you can do it in a way that mathematically guarantees, in some sense, that you're not going to be revealing too much information about any individual user, right? In the sense that if any individual user were to drop out of the database or change their data, then that would have only a very small probabilistic effect on the outputs of this algorithm, right? And, you know, the way that you achieve differential privacy tends to, you know, is often things like, I may ask, like, how many of these users have, you know, colon cancer or something. But then I'll add some random noise to the result. Okay. And so then, you know, adding the random noise, the data is still perfectly good for doing medical statistics. But now it's like even if I knew everyone else's data, I still can't determine whether a particular person has colon cancer or not. Right. whether a particular person has colon cancer or not, right? So he said, you know, and actually you do the same kinds of things to get gentle measurements of quantum states. So Guy said, you know, there seems to be a connection here. And I said, come on. It's like you can, you know, like relate anything to anything else, right? It's, you know, probably just an analogy. But then, you know, we sat down. And in fact, there is a connection. There's a precise mathematical connection between these two problems. You can prove it. You know, it goes in both directions. And then we were actually able to use it to, you know, take work that's been done in differential privacy by people who don't know anything about quantum mechanics, right? Just purely classical CS and use it to get better procedures for shadow tomography. That's really cool. Is that online? Not yet. It's another thing on my stack to write up. It's like another somatical way. Yeah, well, you know, we will try to write it up this summer. All right, cool. So moving to one of the more poorly named CS problems that we talked about over email, the P versus NP problem. I heard you describe this because it can sound really complicated, but I heard you describe it once as, for every efficiently checkable problem, is it efficiently solved? Yeah. And I thought that was a good way to describe it. Yeah. I mean, that's just the standard way to you know say what this problem means right but uh for those why does it matter i guess yeah okay well i i think it's you know uh a strong contender for the most important unsolved problem in math you know of this century uh uh so uh uh so np right stands for non-deterministic polynomial time as i said we're not as good as naming things terrible yeah right but it's uh all the problems were you know if i told you the answer you could check it efficiently what we mean by efficiently in computer science is like by an algorithm that uses a number of steps that scales at most like the size of the problem raised to some fixed power. We call that a polynomial time algorithm. That's kind of our rough and ready definition. It doesn't always correspond in practice to efficient, but it's a pretty... Yeah, exactly. It's ballpark. And it's like if we can't even answer this then we're not going to answer the more refined questions either right so uh uh you know np is all the problems that are efficiently solvable right they actually have an algorithm that will find the answer right many steps so a good example of an np problem would be factoring right i give you an enormous number i ask like uh what are its prime factors right that problem happens to underlie much of modern cryptography right a good example of a problem in p you know if i just give you a number and i ask you whether it's prime or not but not define the factors then that actually has a fast algorithm. It was only proven to be in P 16 years ago, you know, in a big breakthrough. Okay. So, you know, so that's an illustration of how it could be very, very non-obvious to figure out which problems have these efficient algorithms and which don't. Right. And so in particular, you know, like I think as soon as anyone, as soon as a lay person understands the p versus np question i think most of them would say well of course you know there's not going to be an efficient way to solve every problem that's efficiently checkable right why are you even asking that right i mean like a jigsaw puzzle right obviously it's a lot easier to look at you know a jigsaw puzzle that your friend did and say oh yeah good job looks like you finished it, than to actually do it yourself. Same with a Sudoku puzzle, same with breaking a cryptographic code, same with solving some optimization problem like optimizing an airline schedule that may involve satisfying some enormous number of constraints you know or as many of them as you can right when they conflict with each other right but it's not proven not to be possible that's right that's right no one has ruled out that a fast such algorithm could exist you know essentially you know it's very very hard to prove a negative right you know occasionally we can do it, but it's, you know, it tends to be much harder, right? And, you know, if something is possible, you just have to show how to do it, right? But to prove that something is not possible, you have to, in some sense, understand the space of all the possible ways that it could have been done, right? And give some general argument why none of them could work. So sometimes we can do that. It's not like we've made no progress, but we're a long, long way from being able to prove things like P not equal to NP, I think. I like to say that if we were physicists, we would have just declared P not equal to NP to be a law of nature. We would have just been done with it. Yeah, Feynman would have declared it. Yeah, that's right, right. So, you know, well, like the second law of thermodynamics. Yeah. No, you know, we could have given ourselves Nobel Prizes for our discovery of the law. And later, if it turned out that, oh, actually, P equals NP, there is a fast way to solve all these problems, well, then we could just give ourselves more Nobel Prizes for the law's overthrow, right? But, you know, there's one thing you learn in an interdisciplinary subject, like quantum computing, is, you know, like there are differences in terminology and culture between fields, right? What the physicists call law, we call a conjecture. Right. Yeah. I mean, it's increasingly hard to draw the lines in between the two as well. Yeah. CS, math, physics. Oh, yeah. Well, no, I mean, I make fun of my brothers and sisters in physics all the time, you know, only because I love them, of course. But, you know, but in fact, you know, large parts of physics and CS have been coming together in the last decades. You know, partly statistical physics made this very, very deep connection between like spin glasses and condensed matter physics and combinatorial optimization problems, right? And you can understand what many algorithms are doing using physical analogies. And then, of course, quantum computing, right computing was this enormous intersection where suddenly these fields were just thrust together and they had to quickly learn each other's terminology and frame of reference. And that's a good part of what I you know, they just want to know like, well, what are P and NP, right? And what are the basics of, you know, like, uh, undergraduate level computer science. Right. But, uh, what's, what's cool is that, you know, like I can, um, uh, talk to string theorists, let's say, right. And they know this, you know, like staggering, you know, tower of knowledge that, you know, that I don't know, that I'm only at the lowest foothills of. And yet suddenly they too need to know about computer science. They have to respect you. We have something to talk about. We did a podcast with Leonard Susskind that's not out yet. He's the perfect example of someone who has been pushing this intersection, maybe even more aggressively than I've been. Yeah, possibly. I'm like, every time I talk to him, I'm like, slow down, Lenny. You know, computer science is not quite the future of all of physics. And he's like, it absolutely is. We didn't even get that far. Yeah, yeah, right, right. But I do have a question related to his work. So he talks about this holographic principle, right? Right. How does that relate to the firewall paradox? I couldn't quite grasp the two together. This is a big discussion. All right. The holographic principle is this general phenomenon where often you write down a physical theory in some number of dimensions, involving, let's say, a three-dimensional space. And then it turns out to be dual in some sense to a completely different looking physical theory, which is defined on the boundary of that space, right? So like even in a different number, one fewer dimensions, right? And the first theory, the one that's in the bulk, as they say, right, in the interior involves gravity. So it's a quantum theory of gravity where it can have things like black holes that form and evaporate. Whereas the theory that's on the boundary is a, you know, pretty ordinary quantum field theory, meaning it has no gravity and it's a flat space time, right? So, you know, these two theories look totally different. Right. And, you know, what do you even mean in saying that they're the same thing? Right. Like literally the same information. Right. Right. It's very confusing. Well, you mean that there's a one to one mapping between states of the first theory and states of the second theory. Right. And this mapping is non-local. Right. Like like I I could have a little particle here inside of the bulk, and yet in the boundary theory, that would correspond to some enormous smeared out thing, right? The mapping between the bulk theory and the boundary theory, in recent years, people realize that it is literally an example of one of these quantum error correcting codes that I told you about before that's you know same things that one would need in building a quantum computer right it is uh you know uh the whole point of an error correcting code is that you take like a local you know one bit and you smear it out yeah you represent it with a large number of bits yeah right uh and so so so this is uh you know and this is also what happens in a hologram, hence the name holographic principle. So there's this smeared out representation of everything that's happening in the interior, which is represented on the boundary. And this is the most precise definition that the string theorists are able to give of what they mean by quantum gravity, right? That they say, well, you know, what we really mean by quantum gravity is you define this theory on the boundary, which they more or less know how to do. And then somehow there's this thing in the bulk that's due to that. Right. And, you know, and like, right. So, again, you know, the different culture, different standards. Yeah, for sure. You know, they don't even have like a rigorous independent definition of this bulk theory. But, but what they can do is in various special cases, they can calculate things in the bulk theory, and then they can calculate the same thing in the boundary theory. And in every single case where they can do the calculation in both places, they get the same answer. Okay. So this is what leads them to say. So they're like, good enough. Yeah, good enough for them. Yeah. How does that relate to the firewall? Right. So the firewall paradox is this, it's sort of like a modern refinement of Stephen Hawking's, you know, original black hole information paradox from the 1970s. Like Hawking radiation. Right, right. So, so, so in, well, yeah, so shortly after he discovered Hawking radiation, you know, in 1975, Hawking, you know, wrote a paper that posed the information paradox or puzzle of black holes, which is basically just the question, how does information ever get out of a black hole? Right. Now, why does it have to get out? Well, if we believe that quantum mechanics describes everything in the universe, you know, quantum mechanics, you know, except possibly when a measurement is made. Except when you observe anything. Yeah, exactly. Well, if you believe in the many worlds theory, then even a measurement is just another ordinary thing where you split into multiple branches. But let's leave that aside, right? Any isolated physical system is supposed to evolve in a completely reversible way, right? It may be very hard to reverse in practice, you know, you scramble, it's a lot easier to scramble an egg than to unscramble it, right? But in the view of physics since the 19th century, that's merely because, you know, our universe started in a very special state, right, with a very low entropy, right? My friend Sean Carroll likes to say that every time you cook an egg, you're doing an experiment in cosmology, right? You're proving that the Big Bang was in a special state, right? But, you know, but in principle, you know, everything is supposed to be reversible. So in particular, if I drop an encyclopedia into a black hole, you know, then the information, what was written on the pages cannot be deleted from the universe, right? It has to still be there. So then the question is,ity, it goes into some, you know, other bubble universe, you know, and I think people thought about that for a while. But the, you know, a popular point of view nowadays is that ultimately the information does come out, right? come out, right? It comes out in the Hawking radiation, right? Which for a black hole that was the mass of our sun, it would take a mere 10 to the 67 years for this to happen. You know, eventually... We've got time. Yeah, that's right. You know, you have a long enough grant, you could wait, you could see this, right? You know, eventually it would come out, you know, of course, in a very scrambled form. Just like, you know, if I burn a book, right, physics tells us that the information is still there in the smoke and ash. It's not very accessible anymore, but, you know, in principle, it's still there. And so the idea is that a black hole is just another example of this. Okay, but there's a big puzzle because the information, you know, if you were like, you know, floating next to the encyclopedia you would just see it go right past the event horizon of the black hole go you know all the way down into the singularity and then you know it's kind of never you know it doesn't seem like it's ever coming out right how does it get into the hawking radiation in order to come out right and so uh you know this was such such an acute puzzle that it forced people like Lenny Suskind and Gerard Huff in the 1990s to this view called Black Hole Complementarity, which basically says that there are two different ways to look at the same situation, you know, for an observer who's outside the black hole or for an observer who is jumping into black hole or for an observer who is uh uh uh jumping into it with the encyclopedia right and the idea is from the point of view of the first observer uh the information you know the information if you like never even makes it past the event horizon right it just sort of uh gets uh pancak Right, it's like a fly hitting a windshield. I mean, first of all, just because of relativistic time dilation, you're never going to see anything fall into the black hole, right? It'll just get like slower and slower as it nears it, right? You'll never actually see anything go in. And so the idea is from the outside observer's point of view, you could treat the interior of the black hole as not even existing at all, right? Or it's just like some weird and different and scrambled way to rewrite what is happening on the event horizon of the black hole. So this is another example of one of these holographic dualities, right? Where there's two different ways to look at the same physical situation. You know, there's the interior point of view, and then there's two different ways to look at the same physical situation. You know, there's the interior point of view, and then there's the point of view where it's all on the event horizon, right? And so then, you know, but then there are all sorts of puzzles about reconciling these two different points of view, you know, as you could imagine, right? The firewall paradox was, you know, like a particular technical puzzle about how to reconcile these two different points of view. If we had another 20 minutes, I could get into it, but it might might take too long. But in the meantime, you know, people actually do. You know, the other thing they do is that they use this bulk boundary correspondence as sort of a laboratory. So they say, you know, we have a space time where, you know, we have a boundary where we can sort of calculate what's going on. And now let's inside of the bulk of that space time, let's form a black hole. And now let's try to answer all these, you know, enormous conceptual questions about, you know, what is going on inside of a black hole by translating them into questions about what is happening in the boundary theory. Now meaning the boundary of space-time, not the boundary of the black hole. But that's proven very difficult because in some sense what physics wants, what the theory wants is to just answer questions about what is observable by some hypothetical observer who is far away from all the action yeah who can just send in some particles that also all like you know hit each other and stuff and then you know some some other particles come out right you know so like you know this is like a point of view that physicists like to take a lot of they write the you know all of existence is like a giant particle collider, right? You just send some, smash some things into each other. You look at the debris that comes out on the other end, right? But if you're asking what is the experience of someone who jumps into a black hole, then that is inherently not that kind of a question, right? It's not a question about the observer at infinity. It's a question about, you know, someone who is very much in the action. Yeah. Like Alice sends Bob into a black hole. Exactly. And these boundary pictures are just don't seem very good yet at addressing that kind of question. OK, so let's move on to another unanswered question. Yeah, sure. Sure. So you got a bunch of AI related questions from the Internet. Yes. And it seems that people want you to opine about agi so uh let's go with one of them yeah sure uh so anag asks how can we channel ai growth but not weaponize it so in a sense like how do we it seems like they're assuming agi happens um what do you What do you think? I mean, I think that there will be many social issues that we'll have to deal with with AI, or already are having to deal with, even long before we reach the era when AI is near the level of human intelligence. I mean, we're obviously going to have to worry about self-driving cars and all the benefits and also the disruption and issues that those are going to bring. AI for data mining and all of the implications that it has for privacy. Or a deep net denies your loan application, but then no human can explain why your application was turned down, right? So, I mean, these are things that, you know, I think lots of people are thinking about. And, you know, the good thing is that we can try things out in the real world, right? I think we don't normally think of like ethics and morality as experimental sciences, but, you know, but very often, you know, people have moral intuitions about something that, you know, are really bad until they have been checked by experience, right? And so we're going to have to sort of, you know, and we'll have the opportunity to refine our ethical intuitions about all these issues by seeing the ways that AI actually gets deployed. And, you know, I don't think I'm going to shock the world if I say, you know, I hope that we'll find ways to use it for good and not for evil. But, you know, now I have many friends, including, you know, here in the, especially here in the Bay Area, you Area, where I see every time I come to visit here, who are very, very interested in what happens after that, when AI actually reaches the level of human intelligence or exceeds it. And clearly, whenever that happens, then, you know, we are living in a completely different kind of world, right? I mean, you know, think of like the woolly mammoths, right? Once the hominids, you know, start, you know, making their spears and their, you know, bows and arrows, right? Then, you know, life is not the same anymore. And so a lot of my friends in this community are very interested in the question, how can we ensure that once an AI gets created that is sort of at a, you know, or beyond human level, that it sort of shares our values, right? That, you know, it doesn't just, you know, say, okay, my goal was to make paperclips, so I'm going to just destroy the whole earth yeah because you know that's more raw material for paper clips right that it will uh say no i should uh you know the humans created me i should revere them as my you know as my uh uh great although slightly dim-witted ancestors and you know i should let them you know stay in a nice utopia yeah something you know even while i go off and uh you know prove p is not equal to np right do whatever interests me yeah so i mean my my point of view is that if civilization uh survives for long enough eventually we're going to have to deal with these kinds of questions, right? I mean, I see no reason to believe that the human brain, which is the product of all these, you know, weird evolutionary pressures, you know, including like the width of the birth canal and, you know, how much food was available in the ancestral environment and all this stuff, right? There's no reason to believe that we are near the limits of intelligence that are allowed by the laws of stuff, right? There's no reason to believe that we are near the limits of intelligence that are allowed by the laws of physics, right? And so eventually, sure, you know, it could be possible to produce beings that are much more intelligent than we are. And we may have to eventually worry about that. Now, I have to confess that personally, you know, when I think about like the future of civilization, you know, let's say the next 20 years, the next 50 years, I tend to worry less about super intelligence than I do about super stupidity. you know, as, you know, killing ourselves off or, you know, by catastrophic climate change, by nuclear war, or just the world, you know, regressing into, you know, fascism, just giving up on liberal democracy. And of course, we've, you know, seen many distressing signs all over the world that, you know, that there is this kind of backsliding right now. And so I like to say that, you know, that I hope that, you know, my biggest hope is that civilization should only last long enough that, you know, being destroyed by super intelligent robots becomes our biggest. Right. Right. Let that be our worst problem. Right. Of course. It's like this silly mental game where it assumes we've learned nothing along the way. And it just happens every now and then. Well, I mean, look, I wouldn't go that far, right? I mean, I think it's good to have some people thinking about these things, right? Just like there should be people thinking about how could we prevent a catastrophic asteroid impact, right? Or how could we prevent a catastrophic asteroid impact, right? Or, you know, how could we prevent, you know, a bioterror, right? And, you know, and they'll probably discover various interesting things along the way, right? That, you know, will have implications for the world of today, right? I mean, that usually happens when people, you know, let their minds, you know, roam freely over the far future, right? So I'm happy to have people think about this. I just think that, you know, let's, as practice for solving the problem of AI alignment, let's see if we can solve global warming first. Yeah, we'll see how that goes. Yeah, see how it goes. See how it goes yeah it goes man uh all right let's do another twitter question so uh michael berg asks yeah is anyone keeping track of the smallest n such uh that busy beaver n is independent of zf set theory yeah uh he mentions i recall there was some activity after the 2016 article. I assume that was on your blog. Yes, it was. And I'm wondering if 1919 states is still the record. Ah, so, okay, so let me back up and explain what he's talking about. Yeah, thanks. So the busy beaver numbers are, well, they're one of my favorite sequences of numbers since I was a teenager. favorite sequences of numbers since I was a teenager. The nth busy beaver number, you can think of it as the largest finite number of things that could be done by any computer program that is n bits long. So we rule out programs that just go into an infinite loop, right? But we say as long as your program has to eventually halt, then what is the most number of things that it could do before halting? You know, if this program is, say, n bits long, and it's, you know, run on a blank input, okay? So, you know, of course, this could depend on the programming language a bit, but let's just take the original programming language, Turing machines, right? And so then the nth busy beaver number is defined as the largest number of steps that can be taken by any Turing machine with n states, you know, as defined by Alan Turing in 1936, before it halts. And the amazing thing about this function is that it increases more rapidly than any function that could be calculated by any computer program. This is provable, right? So, you know, it is a ridiculously quickly growing function. So like the first four values of the busy beaver function are known right they're like one six twenty one and a hundred and something the fifth one is already not known but it's at least 47 million uh and then the the um the the sixth one already you would need like a stack of exponentials to start to express it. So, you know, so if you're ever in a contest to name the bigger number, you know, and you just say busy beaver of 100, if your opponent does not know about computability theory, you will destroy them. Okay, but now another fascinating thing about this busy beaver sequence, besides, you know, the fact that it grows so rapidly. Yeah. Okay, well, so in some sense, you know, it encodes all, you know, in a certain sense, it encodes all of mathematics. For example, you know, if I wanted to know, you know, is the Riemann hypothesis true, right? You know, well, there's some Turing machine with some number of states that tests the Riemann hypothesis, right? That halts only if it finds a counterexample to it. And then if I knew Busy Beaver for that number of states, then I would just have to run that machine for that number of states, see if it halts, that would answer the Riemann hypothesis, right? So, you know, so So sometimes there's no surprise that this function grows uncomputably rapidly, because it has so many secrets of the universe encoded into it. And furthermore, one can prove that the axioms of set theory can only determine finitely many values of this function. Okay, so in some sense, beyond a certain point, you know, the standard rules of mathematics cannot even prove what are the values of this function. You know, it has some values, because, every Turing machine either halts or it doesn't halt. And yet, you know, in some sense, ring machine either halts or it doesn't halt. And yet, you know, in some sense, we could never know them, right? So a few years ago, I had a master student when I was then at MIT named Adam Yedidia, and I gave him as a thesis project to try to determine, well, what is a concrete bound on the number of states where this busy beaver function just goes off the cliff into unknowability. We may not be able to determine exactly where it happens, but at least we can say, does it happen by at most 10,000 Turing machine with about 8,000 states that does something that's equivalent to just trying out all the possible theorems of set theory, one after the other, and halting if it ever finds a contradiction. Okay, now what does that mean? Well, it means because of Gödel's incompleteness theorem, it means that a set theory can never prove that this machine runs forever. You know, if set theory is consistent, then the machine does run forever. But if set theory were able to prove that, then set theory would be proving its own consistency. That is a no-no. That's exactly what Gödel's second incompleteness theorem says it can't do without being inconsistent. I think I got it. Yeah, okay. Yeah, yeah. So it's kind of like the way to remember it is anyone who brags all about themselves probably has nothing to brag about right you know if if your theory is bragging about its own consistency it means it's inconsistent yeah okay and in a theory could believe it's inconsistent while being consistent gotcha that's possible but not the other way so you know i can't believe it's consistent with uh so so um so so he designed an 8 000 state you know, and this was a lot of software engineering that went, right, you had to like compile down the Turing machine, you know, keep very careful control over the number of states. And so then he and I wrote a paper about this. I put it up on my blog. And then, you know, this, what's cool's cool is that you know a lot of hobbyists were able to look at this say you know maybe they could improve on it in particular there's a guy named stefan arrear and he got it down to a less than 2 000 state machine and i believe that most recently he's gotten it down to under 800 states uh uh in any case all of his he hasn't written a paper about it, but all of his code is available on GitHub. If anyone wants to look at it, even try to improve over what he did. I suspect that there may even be a machine with 10 states that would already exceed the ability of set theory to know what it does. Why do you suspect that? Well, I don't know. I mean, already with five states, there are machines whose behavior seems to hinge on some weird number theory, and no one has yet understood them, right? And we know how rapidly this busy beaver function grows. I mean, the truth is that we don't know, right? But it's somewhere between 500 and 800 or so. This thing goes off the cliff. Cool. Yeah. I actually do have a question about your blog. So from what I can tell, you're basically inactive on social media. Well, I do not have a Twitter account. That's not an accident. Okay. Yeah, that's what I figured. Despite that, or in spite of that, you've been blogging for 10, 15 years? Since 2005. And I guess blogged on some other blogs before that. Okay. Yeah. But I mean, blogs used to be considered social media. That's true. I mean, yeah, I feel like a dinosaur, right? Like back in my day, we just had blogs and we really liked it. We just had blogs and we really liked it, you know. I mean, I feel like so. So my friend Sarah Constantine had a post, I thought a very insightful post about this recently, where she was making the point that blogs are, I think, very much in keeping with the sort of original promise of the internet, the original idea that it was going to be a space where people would discuss things, right? Where they could spell out an argument, you know, by composing some paragraphs of text, right? That would set out what they think and why, you know, take responsibility for what they said, put their name to it. Other people would then respond to it, give counter arguments. It would all stay there. You their name to it. Other people would then respond to it, give counter arguments. It would all stay there. You could search for it. You could find it. You could link to it. Right. It's very much a continuation of the culture of, say, Usenet in the 80s and 90s. And since then, we seem to have moved away from that toward a model of communication on the internet that's a lot more like what offline communication used to be, right? I mean, I've described Twitter as sort of the world's biggest high school, right? It is a, I mean, no, you know, which, you know, doesn't mean it's all bad. In fact, I have wonderful friends who, you know, use Twitter for, you know, to do, you know, very, you know very worthy and great things. I mean, I like to tell them that they're sort of like they bear the same relationship to Twitter as like the 10 righteous men, Bordasadam and Gomorrah, right? But unfortunately, it is not a medium that I think is designed for spelling out an argument, right? Or for sort of explaining carefully where you're coming from. It is almost like designed for ganging up on people, for forming these kind of outrage mobs, which indeed we see that, you know, it is susceptible to these repeated outrage explosions. And I'm not blaming one political side. I think we can find plenty of examples on both ends of the political spectrum of Twitter kind of being used for what I think of as really nasty purposes. think it was really nasty purposes uh and um you know i mean i mean uh tumblr and uh instagram i mean you know you know it's not always nastiness right but they're just sort of you know they're designed for kind of uh you know sharing a photo people click like on it yeah right it's a lot of kind of social signaling it's a lot of building up one's popularity, one's presence. Right. And not sort of discourse. They're not really designed for, you know, carefully clarifying, well, what is it that we really disagree about? Right. Where are we coming from? And that is really what interests me. Right. That is what, you know, I don't always succeed, but that's kind of what I try to do on my blog. I think the problem comes when, you know, we try to have that kind of conversation on the blog, like a really careful conversation where anyone is welcome to contribute, but, you know, they have to play by the ground rules, right, of sort of, you know, have some empathy, understand where other people are coming from. Right. And then if people come into that from the culture of outrage models where they just say, let's just look for the most inflammatory sentence ripped out of context that we can just put all over Twitter to say, you know, look at these blithering idiots. to say, you know, look at these blithering idiots, right? Then, you know, it really, it becomes scary and it becomes much harder to have that kind of discourse where you're really trying to understand the other side. So have you been, yeah, because you've been the victim of this before, right? You could say so. Yeah, or, you know, for better or for worse. I mean, a lot of people who try to do this. For sure, yeah. You know, I mean, a lot of people who try to do this. For sure. In fact, a lot of people have had it much worse than I have. Yeah, absolutely. And has that like, were you on Twitter at one point? No. Okay. No, it just never really tempted me. Interesting. I mean, if I have something to say, I mean, sometimes I just put like little updates on the ends of my blog posts that are kind of like tweets. Yeah. Yeah. Yeah. Okay. Do you have a favorite post? Oh. So I had these posts critiquing information. Sorry, integrated information theory. Okay. Which is a proposed theory of consciousness by uh uh people like julio tenoni and you know i was explaining why i don't think this theory of consciousness works why it solves the problem it's supposed to solve but uh what was great about this post is that you know the uh uh all the experts you know tenoni himself got involved in the discussion uh david chalmers the uh philosopher of consciousness got involved in the comment section and so we kind of had this you know kind of plato's academy thing going right you know like uh um you know just in my blog comment section i feel like we were actually able to make progress on a major issue. Right. You know that that's not all right. I mean, sometimes I write a post that just, you know, some stupid joke or procrastination. But sometimes, you know, when I, you know, have something that I want to get out there, it's nice to have a forum. Yeah, that's great. Yeah. All right. So you suggested this question, so I might as well ask you advice for young people. So you kind of are all across the world, like, you know, you're potentially licensing ideas to companies, but you're within academia and you're you're also, you know, kind of a CS science communicator. So you're across many realms um what is your advice for nerds in general or uh yeah people who want careers in science uh well uh first of all you know if you are um uh currently in high school. Well, I hope you're having a good experience. If you are, that's awesome. Take advantage of it. If you're not, realize that things will get better. Because this is a Y Combinator podcast, I should mention that one of the most influential essays that I ever read was Paul Graham's Why Nerds Are Unpopular. It has an enormous amount of insight, I think. That's the beginning of Hackers and Painters. Yes. So buy his book, but if you don't want to buy it, he's also got it on his web page. And the basic argument that he develops there is that teenagerhood is sort of a creation of the modern world. It used to be that once people would pass through puberty, well, either they would pass through puberty, right? Well, you know, either they would go off and get married, you know, right, that or they would apprentice themselves to some craftsman, or, you know, maybe they'd be working in the fields or whatever, right? But, you know, but but they in any case, they would not be in this sort of environment of high school, which is sort of an artificial environment that we've created. Because we don't know what else to do with these people, right? And, you know, maybe there's some teaching of them that goes on. Although, if you look at how much knowledge the average high school graduate possesses, you know, it can't have been that much. No, retaining not so much. That's right. That's right. So, but what you do get a lot of is sort of popularity contests that are, you know, can be sort of, you know, based on nothing. Right. And yet if you want to do well in it, then you sort of have to devote almost all of your time to this. Right. And so this is that's the core of the right. Right. So a nerd, you know, in in his telling is someone who is in that environment, but who's already thinking about the issues that matter in the wider world yeah and he says basically like they care more about being smart than being popular yeah so um um you know and he says like like it's very hard to accept that that is your priority right because it seems like you know you would give anything right i mean uh you know you would even accept like a lowering of 30 IQ points or something just to not be in the situation that you're in, right? But except if someone actually gave you that choice, would you actually take it? Right. So, but realize that, you know, there is a wider world of, you know, people who are going to appreciate, uh, uh, you know, uh, uh, sort of things that really matter. Right. And, uh, uh, you know, you can try to, uh, get, get to that world sooner depending on your circumstances. So, you know, so I actually left high school early. I got a GED from New York State when I was 15. And I went to a place called Clarkson School in upstate New York, which is a program for high school students who can take courses at Clarkson University and then, you know, apply to college from there. Almost every college rejected me. I mean, this was kind of a bizarre trajectory, but Cornell was nice enough to accept me. How old were you? I was 16 when I started there. You were 16 when you started at Cornell. Yeah, yeah. And then since I already had one year, then I spent three years at Cornell. Okay. And then I went to Berkeley for grad school. Yeah. So I was lucky to be able to leave it a little bit earlier and my parents supported me. Once it became clear that this was what I wanted to do, they warned me, well, look, this is going to make your social life really, really difficult, which turned out to be 100 percent true. But, you know, the I remember telling them at the time, look, you know, my social life already stinks. So, you know, you know, it's I mean, you know, you know, at least I could have, you know, I mean, I mean, I was lucky to have some very, very good, you know, a few very, very good friends in high school, some of whom are still my, my wonderful friends. Right. But, uh, uh, like it was, it was only after, you know, I had been a postdoc for a while that I started finally figuring out, uh, how to drive a car, uh, how to ask someone on a date. So, so I sort of did things in a weird order so when you when you yeah when you wrote about you've written about depression a little bit yeah in your book yeah yeah was that during this period or was that yeah it was pretty much during this period but you know but even starting before i had skipped any grades so so right so that's the thing i felt like i was already in such a uh a um constricted environment, right? That like, at least I could be learning something, you know, CS and math, right? You know, at least I could be in an environment that was, you know, where people cared about the intellectual things that I cared about, right? But realize, you know, once you get into that environment, right, you are not the only one, right? Eventually, you know, once you get into that environment, right, you are not the only one, right? Eventually, you know, you will be able to, you know, a great thing about the modern world is that people can sort themselves, right? And you can find a group of friends who will care about the things that you care about. Yeah. So in other words, you know, put yourself out there and try things. Yeah. Yeah. Cool. All right, Scott. Well, thank you so much for coming in. Yeah, of course. Thank you.