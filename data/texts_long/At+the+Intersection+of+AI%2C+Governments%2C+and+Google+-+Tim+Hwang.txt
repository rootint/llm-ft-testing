 TIM WONG, And so what do you do for your job? So public policy is a pretty fun job. It's a combination of a couple of different things. On one hand, I work a lot with sort of governments and regulators and civil society trying to figure out actually like what Google's position should be on a whole range of issues. Everything from whether or not machine learning is going to take all the jobs to whether or not, you know, we can make sure that these systems are fair and non discriminatory. And then internally, I work with product teams and researchers to kind of keep them apprised of what's happening on the political scene worldwide. Okay. And so what does that mean? Does that mean traveling around and meeting with people? How do you find that? Yeah, it's a lot of meeting with people, actually. So we end up kind of talking with people from a whole range of different kind of sectors and a whole range of different backgrounds, particularly because AI is, you know, this kind of emerging technology. A lot of what we're doing is kind of just trying to assess like how different parts of society are thinking about it. And so I think that with AI and then policy on AI, you've kind of like nested two obscure things that people don't really know what you're talking about. So could you just back up a little bit and explain like what doing policy for Google actually means in the context of AI? Sure, definitely. So, you know, I think the really interesting thing about AI is basically that, you know, a lot of the modern techniques in artificial intelligence, if you even ask people like a decade ago, they would have told you like like this is never going to be a thing it's a complete dead end why are you doing this research and it really has kind of exploded in a completely unexpected way in the last few years and so really a lot of the challenge has been like okay everybody's kind of wrapping their heads around what the you know even what the business impact of the technology is going to be but there's increasingly a lot of people trying to figure out like what the social impact of the technology will be. And I would say policy really sits at that interface between these really cool technological capabilities that are coming about and then like what society in general is going to do about it. And so what would be like a tangible example at Google of like a policy that you guys have worked on to figure out? Sure. So there's a couple of really interesting problems that we've been working on very closely. One of them is this question about fairness in machine learning systems. For example, to give you one really concrete challenge we've been thinking a lot about is in order to de-bias a system, once a machine learning system is behaving in a biased way, one way of trying to deal with it is collecting more diverse data. One of the big problems is when you do that, you end up collecting lots and lots of data about minorities, which raises all these really interesting questions around privacy and what have you. And that ends up being a really interesting problem because it's both a technical challenge, which is like, can you collect an adequately diverse data set? But on the other hand, also this policy question, which is what is society comfortable with you collecting? And what are the practices? And that ends up being a really interesting trade-off that you have to navigate if you're interested in these problems and so what do you actually have to do like are you going doing like user interviews with people or is it just uh guessing yeah part of its user interviews part of it's actually working with like people who know right like it turns out that issues of privacy particularly minority privacy are like not new problems right and so a lot of our work is actually like talking with people who are like experts in that space, right? People have worked on, you know, bias and discrimination questions on the past and a lot of data scientists and trying to get them to talk to one another. Because I think right now what we're really trying to do is kind of bridge these sort of human values on one hand with like a lot of what's happening on the technological side. And so if I'm a company and I'm like, I can't afford a policy guy like Tim, and I will be dealing with large amounts of data that may or may not discriminate against people is that there's like lots of potential points of failure. And like, I think every single interesting point of failure is being investigated right now. But I mean, one of the most common problems is just that you don't adequately think through your data. And so the machine does what the machine does, right, which is trying to optimize against your objective function that you give it. And it'll often maximize in ways that you don't expect. And that is, in fact, part of the problem, right? So, I mean, one of the examples that I always think about is, you know, we have this project that we released. It was called Deep Dream. And one of the problems in computer vision is trying to figure out, like, what the computer actually thinks it sees when it looks at an image. And so you go through this process, and you basically, the whole process and you basically the whole process you showed an image you ask it like what do I have to do this image to make it look more like what you think for example a sandwich looks like and you edit the image slightly and you keep repeating this process until you know kind of you show out like what is the ideal thing that the computer thinks it is and it turns out that when you ask it to see like ask it to reveal what like it thinks a barbell looks like you know barbells always show up with human arms attached to them right yeah and so like that's a really interesting problem right because you've trained barbells on photos yeah that always have someone holding the barbell and so it ends up learning this completely bad representation and what do you got to do i mean a big part of it is just like the consciousness around like oh that can happen right and like how do you interrogate your data set to make sure it doesn't have those problems. And you guys are doing some interesting stuff around adversarial data, right? Yeah, that's right. So, I mean, I think adversarial examples and generative adversarial networks are like some of the hottest points in the research right now. It's almost become a joke that there's like so many what they call GANs out there right now. This is like everybody has a GAN. So what does that mean? What does it stand for? So a general adversarial network. So it's a very particular way of kind of setting up machine learning. But adversarial examples lead to these really fascinating results where, you know, you can take a picture of a panda and that's a classic example. And you edit a couple of the pixels and it like basically like the computer will be like, yep, that's definitely a giraffe. And it still looks like a panda to humans, right? Which is a really fascinating thing. And so what data are you seeding into that image to make it think it's giraffe well a lot of it i think is basically you're editing particular pixels within the image that we know will set off the machine to behave in certain ways so because it turns out basically that like we always assume that a computer will see the same thing that we do just based on the visuals but how we process is actually completely different from from machines this researcher david weinberger did this awesome article recently which is basically trying to argue that like you know machine learning it's it's generating knowledge but one of the most interesting things about it is that it's generating knowledge in maybe a way that like is completely different from our the way our human brains work and like that ends up being a really interesting challenge is like how do you like understand the knowledge that you're getting and how do you understand like the reasoning behind the knowledge that you're getting from machine learning systems well that and maybe that's a sensible segue into like how people are investigating the impact of ai as it relates to like automation and what humans are good at doing and what computers are good at doing yeah right and so when you travel around you meet with people you meet with different countries like how are people gauging the effects of automation and ai right now and and its effects over the next like you know decade yeah i think um so it's an evolving picture yeah right and i think right now i think everybody is just surprised at all of the things that machines can do that we thought that humans were going to be good at for the foreseeable future right so like go is the canonical, but there's all sorts of really interesting kind of like reasoning and other things that like machines are engaging in now. And so one thing I always tell people is basically that everybody always wants to think about AI as if it were like this huge meteor just crashing into the earth, where they're like, what do we do when the AI arrives, right? And it just like, it doesn't in terms of that it doesn't work like that right and in fact like what we really need to get to is like thinking about like how particular you know technical capabilities will map onto the economy and that's what a lot of the work is happening on right now okay and so yeah let's go into some examples yeah sure so so for example one really interesting question is this adversarial examples right which is basically like everybody always assumes that like okay if it can be automated, it definitely will be automated, right? But that's like a fallacy because in certain cases, like you may really worry about the security of your systems, right? So if someone, for example, can like hold up a photo and cause like a security camera to be like, oh, it's definitely Tim, open the door, right? Like that ends up being a real reason why you would not necessarily want to implement a machine learning system for you know access control for instance and so that's actually really interesting because that means that if we don't solve that research problem that means that we will be limited in the kind of domains that machine learning enters into and i think that's what we're really interested in right now is like what are these kind of gateway research questions that if we got through would like totally change the nature of like who when and why someone would implement this stuff. And so are those things collecting the interest in like the momentum of the research community? Because like I can see a certain direction where it becomes incredibly product focused, right? Where I'm like, I'm a researcher, I'm incredibly talented. Like figuring out if the security camera is going to work with an adversarial network, like maybe not, might not be of highest interest to me. Is that like blocking people or is like the general concept enough? I mean, I think right now it's a little bit unevenly divided, right? It turns out that like research interest is not necessarily like policy relevant interest, right? And so in some cases they're overlapping, right? So I think there's a lot of interest in adversarial examples. There's a lot of interest in adversarial examples there's a lot of interest in like what are attacks essentially that you can put on these machines to get them to behave in ways that you don't expect that seems to be a place where like security which is like very much a policy interest will map on quite nestle to security as like a research interest okay but for example things like fairness right like i was talking to a machine learning researcher the other day who is basically like look i could not in good faith advise a grad student to work on machine learning fairness issues because it's not just it's just not considered a serious problem in the field right and like that's just like that has less to do with like the field and more like the norms of the field right and then that that ends up being a big issue right we don't have coverage on certain types of things and in practice may actually really limit like where these technologies are are implemented well i think it's a it's a material issue right now. Like there's a gap between product understanding and like actual deep research. Yeah, that's right. And I say this to a lot of people, like, you know, everybody's always like, so what skills do we need to teach people in the future because of machine learning? And I think like one enormous skill will be like domain knowledge, because like coming up with like a technical capability is is just one part of this huge picture, which is just like, okay, so then how do we actually introduce automation in a way that makes sense to people? And that's a huge task. And so my personal prediction is that interface and how we effectively collaborate with machines, particularly with these two new types of models, how that effectively done is still a big open question and will seem to be increasingly in higher demand as you suddenly have access to these capabilities right so what i've been wondering then is like does for example like you know tensorflow or you know any one of like the the machine learning apis um does that become the new aws for products or do people have to build their own to create like a defensible company? I mean, I think there's still like, so I mean, like cloud services will have the same impact on the economy that they always have. Right. And I think this is one interesting thing is all these companies are now competing for offering cloud ML services. Yeah. And the upshot of that basically is that the like amount of like, don't need a phd in machine learning to get all the benefits from machine learning right and i think that will shape the space for sure okay yeah cool so then what are the other areas like aside from um aside from the first one we talked about for automation and work like where are other people interested well so i think i'm the other thing we're really interested in uh and i'm really interested in is kind of like is it possible to pull off machine learning with less and less data? Right. And so, you know, there's a couple examples of that, but one of them is like one shot learning, right. Where people are basically working on the ability to teach machines, but like a much smaller number of examples. Now that actually has a really big impact on the game because that means that you can implement machine learning effectively in situations where it's's really expensive to collect lots of data. There's also one really cool interface between VR and AI that's happening right now, where the whole idea is there's a project called Universe from OpenAI and another project called DeepMind Lab, which basically, imagine you need to teach a robot to get through a maze. Well, you could have it physically run through that maze millions of times, or you could just have a virtual 3D environment that you cause a computer to run through and it learns how to do that in virtual space and then basically you you put it into uh in practice in in a real robot and so that's a really another exciting way we don't necessarily need like an expensive physical setup to collect the data that you need you know to accomplish tasks in the real world okay so then what like i guess what i'm curious about then is like how are these countries like preparing for this like you know again not a meteor strike but like perhaps a gradual shift over 20 years 30 years um to a very different world than what we have right now yeah and i think you're right now you're seeing like a bunch of different ideas out in the space um you know some for example like basic income right universal basic income which would like fundamentally reshape you know like the social contract and how we think about doing for example like welfare in a whole number of countries and like so you see book proposals like that i think you see a number of proposals that are more like focusing on education so like what are skills that people will need in the space and that ranges everything from like everybody needs to be a programmer to like oh well we need to really encourage like computational thinking right which is like the ability to work effectively with data right and so like there's a couple of different options out there some of the more interesting ones uh that i've heard of that are a little bit more obscure right like so some people have said like oh well maybe we need like automation insurance so in the future your employer will provide you with like a contract that says if your job turns out to be replaced by ai at some point in the future um we'll pay out at some kind of rate right so people are like experimenting with lots of options right now i think what we actually need in the space is like more experimentation so for even proponents of basic income a lot of tell you, like, we actually don't know in practice what this would look like if it were actually rolled out at any level of scale. And so like, I mean, it's cool seeing YCR and a couple other places like experiment with this. And so where, where is the traction happening then with all these experiments? Like I, it seems very limited, but is it all like in Northern Europe? Or I know there's a basic income study in India at this point. Who seems to be focusing most on this area? Yeah, we're seeing a lot of different countries engage in this. I think Northern Europe is kind of leading the way in terms of their willingness to kind of experiment with some of these models. And I think they've got a couple things going for them, right? Like on one hand, I think they have a skilled labor force, right? That like is relatively expensive, expensive right so i think that they are seeking and excited about ai in large part because it's a prospect to bring for example manufacturing back to the country right because it allows them to compete on the same footing as like other countries that have offered like labor for like much lower costs right right so like that's one thing that that's that's good for them i think the other thing that's also encouraging a lot of experiments is that they have a lot more coordination between government, industry, and labor, which is making it more possible to experiment with these sorts of things. So I think in a really interesting case, it turns out that maybe Northern Europe is actually a little bit ahead in its ability to kind of experiment and understand some of these programs. And then as a Google or Alphabet, as this international institution at this point, how are you guys thinking about interacting with different countries as this happens? Yeah. So we're investigating at the moment. Right. So the question is who on the research side should we be working with? Yeah. And what are kind of programs that we could support that will help us give a better handle on this picture? Right. Because I think like, look, ultimately, like it's a technology company. And so we know that we don't have all the talents necessary to evaluate what is a proper social welfare program. But on the other hand, we think it's actually really important that we encourage a better societal understanding of how to deal with these technologies. And so I think we're very much in the mode of how can we support this? And I think that's partially through potentially resources, but also potentially like expertise as well, right? Like we, if you want to know anything about machine learning, we got people who can tell you about that. Now we have to marry that up with people who have a good understanding of how this will impact society, either through economics or otherwise. And do you ever feel like the information you're disseminating is like guiding the conversation and guiding the future or like people are like playing into the game like it's intentional or it's just like opened up i mean i think it's very open right i mean i think like you know i think it's easy particularly in the valley to be like oh my god these big companies but like we're only one part of a much larger larger picture about what's happening in the economy i like totally think that's the case yeah like you know like we talk about ai and automation but we might also want to talk about like demographic shifts happening in the economy like what's it mean that we have an aging workforce right or like what's it mean that we have like falling workforce participation in the united states right like those are actually trends that like they are almost as large as like what someone comes up with a lab and presents in a machine learning conference and so like i think it's actually really important that like we look at this all in a bigger perspective okay and so what do you guys do to like keep that in mind i imagine you just have like a whole policy team to manage that yeah it's kind of what we're responsible for is like keeping track of a lot of this stuff right and like getting a better understanding of like who is researching in the space because as i said I said, I think we're still really early on in this technology. Again, if you had asked someone 10 years ago whether or not neural nets were gonna be a thing, they'd be like, yeah, I don't know, it probably wouldn't work, right? But if we're at a phase right now where suddenly it has become technically real, I think now that understanding is just starting to percolate out to a bunch of other fields who are like okay well i guess we now we've got to assess what's going on and so do you see companies and organizations and countries like locking their gates because they're scared because it feels new like it's obviously massively hyped but there's also some reality behind it um has there been a negative reaction yeah i wouldn't say so i mean i think by and large what we're seeing is that a lot of governments are just really curious they actually want a better understanding of what's going on okay so in many cases i think what we're seeing is like people asking you know like what is happening in the technology okay so i think you know the phase of what to do about it is still on this way right so that you like give them you know the powerpoint deck and they're like oh okay i kind of get how this works and then they go home you know whatever to like japan and they're like, and they're like, okay, they think about it? Well, yeah, I think so. I mean, this is how government progresses, right? It's like, I think, like, they ask questions, they get information, and then there's, like, a long process of figuring out what you do around it. Right. But, I mean, that isn't to say, like, there isn't, like, laws and other regulations So one of the most interesting aspects of the GDPR, which is a new privacy regulation in Europe, is the potential for this what they call kind of a right to explanation. So the idea is for certain kinds of automated decision making, it might be so significant as to require or give citizens the right for that system to be able to produce some kind of human understandable explanation for what it's doing. And like that raises all sorts of interesting challenges about like how you actually pull that off and so like i would say that i don't want to make it sound like no governments are taking action but i think like that's that's the beginning part of it right like and i think like by and large the stance of most governments have been to like understand what's going on do you think someone's doing it particularly well now? Yeah, I mean, I was really excited by some of the stuff happening out of the UK. So last year, they actually did a report that was on kind of like giving an account of like the risks and opportunities from artificial intelligence. And I think there's like a really good account of that. So and then last year with the under the Obama administration, there was a really good report that they did as well on the topic. under the Obama administration, there was a really good report that they did as well on the topic. Okay. And so, like, can you go specific on that? Yeah, sure. So, I mean, I think what we at least had in the U.S. case, right, was basically a report that, like, really focused in on, like, okay, what are the real concrete risks here? Yeah. And part of the idea was to pivot away from discussions that were just like okay the main thing we've got to talk about here is whether or not robots are going to destroy us right like or decide to take over right yeah which i agree is like kind of an interesting scenario to consider but like you're right like there's a lot of like core near-term problems that need to be dealt with and i think that was one thing they did that was very useful so well aside from the stuff we've talked about where what do you find to be particularly exciting both like here like at a you know local bay area level uh as far as like research and then at you know global international research level moving this stuff forward yeah so i think there's two things that i find really interesting right now one of them uh is the intersection of machine learning and art right so like largely this is a technology we've been using to solve like pretty pragmatic things, right? Which is like how do we ensure that we can adequately recognize like cats in photos? But like what's really interesting is a bunch of people are kind of playing around right now with the intersection between like, oh, could I use this for like artistic purposes? So there's a really fun project, Google has this project called AI Exper ai experiments which is a lot of kind of like small things like this which kind of demonstrate the kind of artistic possibilities of technology we also have another program called magenta which is looking into machine learning and music and like whether or not there's ways of kind of creating better creative collaboration between humans and machines on that front hmm and and have you experimented with it personally uh yeah some of it's really fun there's one project which is basically like a melody generator like you play some notes on a piano and then the computer will play alongside you like harmonize with you yeah exactly right right and so you kind of like improvise with the with the computer which is super cool uh there's another project called marauder cam which you get on your phone okay which is like you take a couple photos of things in the room and it produces this like bopping like electronic dance hit that has like that uses the words of the objects in the room as like a rhyming you know set of lyrics oh super cool yeah and a great example of like how the technology is becoming like really accessible because again if you wanted to like do that like 10 years ago it would have required like a huge amount of money and like you know a bunch of phds to try to work on this problem right yeah i've been fascinated with that like how it's become distributed just even in the past like year like i you know i told you about all the speech to text stuff that i'm working on yeah man like the fidelity of it is shocking yeah just in like one year right right and so it's gotten like way better which i think is super interesting um i think the other thing is also like trying to figure out like uh there's these like really unexpected things that emerge too so the the other thing that I think is really cool right now is there's a paper that came out from DeepMind, I think earlier this year, that was kind of like, if you get two machines to talk to one another, they will eventually, and you can set up another computer to basically say like, oh, I can read what you're saying. I can't read what you're saying. You can basically train these two systems to come up without even necessarily needing to program encryption into the computers, which is also super cool as well. They learn how to accomplish that task. And it's not very good encryption, but the basics are basically learned by these systems so long as you give them good reinforcement on, okay, that's still cognizable. I can still understand what you're saying versus a third party being like, oh, I can't do that. Oh, man. And so do you have thoughts on like how this will become distributed in such a way that any day like we'll be interacting with it in our everyday lives as just like fun projects like will it be existing in the art space will like be uh you know like training new programming languages for folks to work on when they're younger yeah i mean i think like there's there's you know i was talking to p Norvig, who is like one of the researchers we have is like one of the, you know, founding fathers of AI. And he had this really interesting thought, which is basically that, like, we may be approaching the period where we actually have to entirely rethink how we teach computer science, because like machine learning is such a powerful tool. And also cognitively, it works in a way that's like totally, you know, counterintuitive, right? So like, I do less software than I used to, but like definitely when I was in the trenches doing coding work, it was very much like, okay, like, let's get a bunch of smart people in the room, let's come up with a bunch of rules, and then like, let's get those rules into the machine, versus as much different kind of mode of thought, right? Which is basically like, let's present the machine with a bunch of examples and then verify whether or not the machine has learned the proper lesson. And so his idea is like, actually, we may actually really want to think about how we think about CS from the very first moment you step into a classroom, which I think is a super compelling idea because it was always thought of like, oh, machine learning is just going to become this complement to how you do programming. But I wonder whether or not software in the future will actually look more and more like machine learning focused, right? And like you actually change your entire approach to programming systems. Oh man, that's fascinating. I mean, it's already kind of gone that way in that like many CS programs are so technical, you actually never build a web app. Yeah, that's right. Like you can go through Stanford CS and never build a web app. Yeah, and I think it's a very natural trend that we're getting to higher and higher levels of abstraction. So in some ways, machine learning is this ultimate level of abstraction where it's like, even if you wanted to understand what's happening in a neural net, it might be actually kind of difficult to do so, right? Yeah, I mean, I guess so. But I see it becoming like, there's just new ways of thinking about how you structure the code because at a certain point things will just become abstracted and you won't have to do it anymore yeah like i think about it in the context of like you know parse creating an api right like that will exist for many things like i could see a like a squarespace type thing but for like a proper web app right and you just drag your database in and you never even think about it that's right yeah yeah and so ironically like programmers might lose their jobs way sooner than they think um well and particularly interesting because like we actually like this this emerging research right now which is using machine learning to train machine learning systems yeah raises like this meta level where like right now there's a lot of handwork that goes into building a model so it learns the right representations but like if a machine can do that in the future, it gets even more abstracted where you may not even need to be a specialist because in some ways the machine kind of codes itself. So I think one thing that a lot of people are curious about is how you're actually going to build a business around AI. So just for like, we can start broad and then go more narrow. Do you think AI will be dominated by massive companies like Google, Facebook? Or will, you know, there'll be very successful AI products on a small scale? Yeah. So I actually think that there's actually like a ton of room for competition here. And it'd be interesting to see how all the various companies find their niches in the space. I think there's two really interesting trends right now, right? I think one of them is the emergence of like cloud platforms, right? Where basically all the companies have said, like, there's a long tail of uses that we would never be able to like take advantage of, but we may be able to like provide the services that like power those services, right? And so like, for example, Google is offering like cloud ml right now and i think it's a really interesting development in the space which i think creates a lot of opportunity because it means that there's all these industries that might not necessarily be like ai industries that might be able to like seize the benefit from the technology so that seems like a pretty huge thing to me um i think a second one which is really interesting is like some of the one-shot learning stuff we talked about earlier right which is basically that the amount of data you need to pull off certain types of machine learning applications is going down over time and what that tells me is that there might not be necessarily a first mover advantage in this space where you may actually have collected a bunch of data but if it's not the relevant data and also the amount of data you need is going down over time then the real big challenge is less data and actually more your ability to build like good interfaces and good experiences around the technology. Yeah. I've been wondering about that, like as I play around with it and build like tiny little web apps and stuff, like how much of this is just entirely reliant on the product as like it's all plug and play. And so to a certain extent, like folks can almost guess which techniques you're implementing, which APIs you're using, and if they're faster with better engineers and then they have like the magic touch of like the product person uh i don't see any reason why they can't just jump ahead yeah right right and i think we're maybe fooled by like the nature of the field right now where it's like ah we got to get like the most researchers to go and compete on this thing and like that is like a big important part of it because they're producing a lot of like the breakthroughs in the space but it is I think important to consider too that like there's still like this big open question of like how this actually becomes like effectively part of product oh well absolutely I mean we did an interview at Baidu and it may or may not come out before yours so we might do like a fourth wall jump, but, um, they explicitly are focusing on things for over a hundred million people and you're like, oh, okay, well I can build plenty of successful startups or businesses for less than a hundred million, maybe even a million. Um, and so, yeah, I think there are just all these fantastic opportunities for people. And yet folks seem to be focusing on very similar implementations you know whether it's like chatbot or like you know customer service which i guess is effectively the same thing um why do you think that is is it they just like follow what seems to be like the market leader or these like the most obvious yeah i think people are also still trying to figure it out right like um and i can't i think we can't avoid like that ai is like a technology but ai is also like a like a position it's a marketing position right which i think is actually like a really key part of the picture right it's like why do we think about like siri or like the google assistant as like ais but we don't necessarily think about like the facebook news feed as an ai right like these are all systems that are all powered by machine learning right but there's something about like it's it's representation as like oh yeah this is a machine that talks to you right that like makes our brain snap immediately to like pop culture you know equals ai right and then that ends up being a really big part of it too is that there's a lot of incentives to like correspond to what we think of as AI. Even though like some of the most powerful AI applications may not even come in the form of like a personified, you know, personality. Well, I think that's a super interesting angle. It's like out here, seemingly, it makes sense to like raise your money as like an AI business. But like when you look at Facebook, right? Facebook, if you log in, doesn't say AI anywhere. And clearly they have a lot of people using it. So I wonder if it is like a massive positioning thing that many companies do end up missing because you just have to get like the nerdy people interested in it to sell it, to raise the money if you're going to do venture backed or whatever. But then your end user is like, why am I paying all this money for this chat bot? That's like this thing. I mean like for example, yeah, if you wanna talk about one of the most critical applications of machine learning to date, it's like spam filters, right? Like spam is like this incredibly huge systemic problem on the internet. It is like largely contended with by machine learning right now. Like that's like largely contended with by machine learning right now like that's like largely the tools that we use to deal with it and like that's like an application that we never think about right like so i mean like with many technologies the most important applications will be some of the least visible hmm so what um what are you excited about what are you going to build what are you going to build with ai space yeah uh i gotta think about it some more i mean i you know i'm really interested in these kind of like small scale machine learning projects I think we might have talked about it earlier but like we have this really crazy story where it turned out that there was this cucumber farm in Japan that was using machine learning to build like a really cheap machine learning like robot that would sort cucumbers because it turns out like cucumber sorting is a really big problem in the cucumber farming space and that was basically just trained using like 3,000 sorting is a really big problem in the machine in the in the cucumber farming space right and and that was basically just trained using like 3 000 or 4 000 like photos of cucumbers yeah uh and that was sufficient to train a model to do but like a pretty good job at like sorting cucumbers and like so like i'm really interested in this kind of like artisanal machine learning where like it's like what are these kind of like very specific daily problems that i have and it it's a good way of, I think, wrapping my head around like, okay, what are actually going to be like the practical uses? Not necessarily like the like Cadillac uses that I think we're seeing right now, which are like the demonstration uses of the technology. And then you can open up like Tim's General Store online. Yeah, that's right. And people like download like Tim's Cucumber app. Right. right yeah i mean uh my uh i cracked my iphone uh earlier and um was getting it fixed this morning and the guy had an entire box of assorted iphone screws from from literally like an iphone you know iphone one uh to an iphone 7 now and these are just like he's got like a side hustle uh buying and selling iphones that are like broken online and if they're totally damaged he just like strips all the components. But he spent like half an hour, like trying to figure out what screw would fit. So like, there you go. You can like use like Tim screw identifier. Right, right. It's super handy stuff. Yeah, I think it will be like a lot of small things like that. And what's particularly interesting is like, going back to a little bit what we're talking about earlier like what is the cost of solving a problem through machine learning right and what is the cost of solving a problem through like traditional coding right that's actually maybe one way of thinking about the problem right like for example for computer vision right like now the economies are way in favor of machine learning it's just way easier to design an effective machine learning image recognition system with yeah with ml than it is with like traditional kind of coding techniques and i think that's actually one really interesting way of thinking about is for a given task how long until machine learning is like the preferred way of solving this problem with the computer it totally makes sense as like new kinds of entrepreneurs pop up in these like very small niche things that are essentially like one developer projects that previously like might've even seemed like way too laborious to spend your time engineering. Like you're never going to pay someone to do it. You're not going to do it yourself, but you know, you start plugging into like these cloud ML things and all of a sudden you have this app. As far as distribution, I don't know. Like I've heard more and more people talking about about localizing certain things to the device, which makes them amazing. Have you experimented with that yet? Yeah, so we're actually working on a little bit of research around that. I haven't played around with it myself. But, for example, there's a couple of papers around what they call federated learning, which is exactly working on this premise, which is the bet is, okay, well, what happens in the future where the edges of our network like the phones like have way more powerful processing power like is it possible for us to basically do the majority of the training for these systems like on device and with like basically a lot less data kind of like flowing into the cloud and the idea was basically like the local model would update and it would share its learnings with all the other devices in the network. And it's like a really interesting way of thinking about how you actually do this, because what you ideally want to have is models that are loaded on the device and can also train on the device as well. Because right now, one of the ironies is that there's a big disparity between training, which is computationally intensive, data intensive, and then actual execution right which can be actually like pretty low low uh computational it also creates a giant latency problem with everything that's like in big quotes ai right now like you know most people if you give them siri they're like oh it's constantly broken but if you could communicate with it in a way that's like hey you didn't understand let me go again afterward. All of a sudden the experience is entirely different. Yeah. And latency ends up being really key, not just for like conversational interfaces, but you think about like, you know, for example, like how do we deal with like using this in medical, right? Where you may need a response really soon if you're going to use it for like diagnosis or whatever. Totally. Like if this thing turns into a robot surgeon arm and i move it to the amazon like i can't rely on my like you know hot spot yeah to connect it that's right yeah yeah and so yeah i think again we're like talking about implementation which ends up being like this really big piece of the ai picture which is still being worked out like we know we can get machines to do these remarkable things the question is like what do people actually want out of it so i guess one of the last questions I have for you is people are interested in AI machine learning across the board, or at least people paying attention to this are into it. If someone wants to get more into it and they're thinking about like, how do I position myself? Like, what should I pay attention to? Where should I focus? Because like, you know, now tens of thousands of people are checking it out. What would you say? What would you focus on? So I think there's two really interesting problems in the space right now that like desperately need more people to get involved in and more people to kind of like organize events around. Okay. So one of them is I think this like security thing, right? Where like in the traditional computer security space, we've got like events like Capture the Flag, where people can kind of like show their metal in their ability to kind of like secure and compromise systems i actually think we really need that in the machine learning space and i would be really excited to see that which is like so imagine a game where like you have to train a machine learning model on a set of data and then people will take turns trying to like get past your computer vision systems which i think would be super cool to do. And I think like that's one big piece of it that I think would be really cool for people to work on. I think the second thing that's about to be in really strong demand is thinking about the visual dimension of this, right. Which is like, it happens on a couple levels. That's both like the interface of how you work with machine learning systems, but also just visually how you represent a neural net. Like if you've read the technical papers, one of the things that you'll see is just like, that's largely written by machine learning experts. And so they don't really have a good sense of like, how do you visually portray what a neural net is doing? And that stuff ends up being incredibly important for people to both understand the technology and also be able to use it effectively. And so I think that's another thing that's about to come on the way is basically a really high demand for people who understand this research and could give it good voice in terms of representing it visually. And then if someone isn't into machine learning yet, what would you recommend they read, study, watch? What should they check out? So I mean, I think it's really nice because we're now living in a world where there's a lot more resources for how to learn about machine learning. So I'm a huge fan of Ian Goodfellow's textbook on deep learning. It was really funny. I was in Cambridge picking up a physical copy of this textbook because MIT Press is the publishers. And the guy selling me the book was like, this is like the Harry Potter of technical guides because it had been like flying off shelves so aggressively. So it's really good though. Its reputation is very well deserved. One of the things I've been thinking a lot about is kind of like the history of all this, right? Like it's important to recognize that like AI has been through this hype cycle before and there've been long AI winters where this technology has totally oversold itself. And it's like important to understand those dynamics. So two books that I'll mention, one of them is John Markoff's Machines of Loving Grace, which is all about the history of AI, and particularly its competition with the notion of IA, intelligence augmentation, which I think is a really interesting battle that we're having right now in terms of what this technology is really about and what it should be used for. A second book that's just great, which is also by MIT Press, is Cybernetic Revolutionaries, which talks about basically the Chilean Allende government. So it's basically the socialist government during the mid-20th century. And they tried to basically set up a project called Project Cybersyn where they were like, let's automate the entire economy. So all factories will have to produce data links that will connect to a single central command center where we will like actively control the economy and it's a great initial another example of kind of like oh like kind of like the the history of cybernetics but also it's like implications for like what people try to do back then that i think useful for like you know making sure we understand what the limitations of the technology are today that's very neat i haven't read that i will absolutely check it out. Cool, man. So if anyone wants to follow you online, where do they go? Oh, sure. I'm on my website is at timhwang, T-I-M-H-W-A-N-G dot O-R-G. I'm not the Korean pop star of the same name. And I'm also on Twitter at Tim H So at T-I-M-H-W-A-N-G. Very cool. All right. Thanks, dude. Yeah. Thanks for having me, Craig.