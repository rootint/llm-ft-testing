 Hey, today we have Wojciech Zaremba and we're going to talk about AI. So Wojciech, could you give us a quick background? I'm a founder at OpenAI. I'm working on robotics. I think that deep learning and AI is a great application for robotics. Prior to that, I spent a year at Google Brain and I spent a year at Facebook AI Research. And same time I graduated from, I have finished my PhD at NYU. Can you explain how you pulled that off? That seems pretty rare. So the great thing about both of these organizations is that they are focused on research. So throughout my PhD, I was actually publishing papers over there. I highly recommend both organizations as well as, of course, OpenAI. Yeah, okay. So most people probably don't know what OpenAI is. So could you just give that quick explanation? So OpenAI focuses on building AI for the good of humanity. zainteresuje się budowaniem AI dla dobra ludzkości. Jesteśmy grupą naukowców i inżynierów, współpracujących razem, którzy próbują wymyślić, jakie są niepełnosprawne części generalnej inteligencji artystycznej i jak je budować w sposób, który będzie maksymalnie beneficjent dla ludzkości jako całości. and how to build it in a way that would be maximally beneficial to humanity as a whole. OpenAI is greatly supported by Elon Musk and Sam Altman. In total, we gather an investment of $1 billion in the group. Which is quite a lot. And so what are, I mean, I know some, but what are the OpenAI projects? So there is several large projects going on. Simultaneously, we are doing also basic research. So let me first enumerate large projects. These are robotics. So in terms of robotics, we are working on manipulation. We think that manipulation is one of the parts of robotics which is the most unresolved. Sorry, just to clarify, what does that mean exactly? It means that in robotics, there are essentially three major families of tasks. One is locomotion, which means how to move from, let's say, how to walk, how to move from point A to point B. Second is navigation. It's, say, you are moving in the complicated environment, such as, for instance, a flat or a building and you have to figure out actually to which which rooms which rooms have you visited before which not and where to go and the last one is manipulation so it means you want to grasp an object, let's say, open an object, place objects in various locations. And the third one is the one which is currently the most difficult. So it turns out that when it comes to arbitrary objects, current robots are unable to just grasp an arbitrary object. For any object, it's possible to hand code a single solution. an arbitrary object. For any object, it's possible to hand code a single solution. So say as long as, let's say in a factory, if you have the same object, like, I don't know, we are producing glasses, and there exists the hand code solution to it, there is a way to, by code, to write the program saying, let's place a hand in the middle of the glass and then let's close it but there is no way so far to write a program such that it would be able to grasp an arbitrary object okay gotcha and then um just very quickly the other open a ai projects going on so another one has to do with playing a complicated computer game. And the third one has to do with playing large number of computer games. And you might ask why it's interesting. And in some sense, I would like to see that. So human is, has an incredible skill of being able to learn extremely quickly. And it has to do with a prior experience. So let's say even if you haven't played ever a volleyball, if you try it out for the first time within 10 or 15 minutes, you would be able to grasp how to actually how to play and it has to do with all the prior experience that you have from from different games if you would put the child or like if you would put an infant on the volleyball court and ask ask him or her to play it would fail miserably but i mean due to the fact that it has experience coming from large number of other games or let's say other live situations, it's able to actually transfer all the knowledge. So at OpenAI, we're able to pull together a large number of computer games and computer games can be it's quite easy to quantify how good you're in the computer game currently best AI system so so first of all it's possible for many computer games to write the program that solves it pretty well or place it well. There are also results from, there are results in terms of reinforcement learning or in terms of so-called deep reinforcement learning showing that it's possible to learn how to play a computer game. These are the initial results are coming from DeepMind. But simultaneously, it takes extremely long time, like in terms of real-time execution, to learn to play computer games. So for instance, Atari games, for instance, Atari games, for instance, in terms of real-time execution, it takes something around three years of play to learn to play simple games. I mean, it can be hugely paralyzed, therefore it takes few days to train it on current computers, but it's way shorter for human. In 10 minutes, we can kind of... Teach it how to play and win? Yes. Okay. And is that through you giving it feedback? So the way how it works in case of computer games, the feedback comes from the score. So it looks at the score in the game and tries to optimize it. And I'd say that's kind of reasonable, but I would say simultaneous is not that satisfying to me. So the reason why it's not that satisfying to me, so the assumption underlying reinforcement learning is that there is some environment And environment, you are an agent and you are acting in environment by executing actions and getting rewards from the environment. And the rewards might be taught as let's say pleasure or so. And the main issue is that it's actually not that easy to figure out what are the rewards in the real world. Further on, other underlying assumption is in being able to reset environment to kind of get to repetitive the same situation. And so the system can try thousands or millions of times to actually finish a game. So there are some small discrepancies. People also believe that it might be possible somehow to hard-code into system rewards, but I would say that's actually one of the big issues that it's kind of unresolved. When I look how my nephew plays computer game, he actually doesn't look on score because he cannot read. And still, my nephew, they can play pretty well. So, I mean, you can say maybe reward is somewhat different. Maybe reward comes from seeing a nice, hearing nice voice in the game or so. But I would say that's something what is very unclear how to build a system and what system should optimize. So in some sense, if we have a metric that we want to optimize, it's possible to build a system that could optimize for it. But it turns out that in many cases it's not that easy. And I would say that's actually one of the motivations why I wanted to work on robotics because in case of robotics, it's way closer to the system that we care about. So what I mean by that, for instance, let's say you would like your robot to repair Scramble X for you. And so the question is, so how should I build a reward? And in computer games, actually, nice thing is you are getting reward extremely frequently. So let's say anytime you kill an enemy or let's say won't die, it's quite great. But in case of Scrambling Eggs, it would mean, or the way how people write rewards for systems, it would mean distance from hand to a pen. Then let's say somehow you have to quantify if you were able to crack open an egg, or let's say if you fried it sufficiently. And how to kind of quantify it turns out to be extremely difficult. And also there is no way even to reset the system. How to reset the system to the same place. So, okay, these are like fundamental issues, and the reason why I'm personally interested in robotics is thinking that actually these challenges will tell us how to solve. So let's start by defining a couple of things. So what is artificial intelligence? What is machine learning? And then what is deep learning? Okay. These are pretty good. And these are pretty good questions. So artificial intelligence is actually extremely broad. It's an extremely broad domain, and machine learning is a sub-part of this domain. And in essence, artificial intelligence consists of writing any software that tries to solve some problems through some intelligence. It might be hand-coded solution, rules, rule-based system. Yeah, so pretty much it's actually very hard to say what is not artificial intelligence. You can say that... so initial version for instance of Google search was based on... It was avoiding any machine learning and it was... There was like a well-defined algorithm called PageRank and essentially PageRank counts how many incoming links are from other websites and that's artificial intelligence. It's an essential system that does intelligent things for you. Then over the time Google search started to use machine learning because it helps to improve results. At theultaneously, they wanted to avoid it for some time as it's more difficult to interpret the results and it's more difficult to actually understand what system does. So what is machine learning? Machine learning, it's essentially a way of building or let's say that's a, essentially you have data and you would like to generate based on data program with some behavior. So like the most common example which which is still sub-branch of machine learning, so-called supervised learning. So you have pairs of examples, X, Y, which means like, I would like to map X to Y, for instance, either if given email is spam or not spam, or let's say even image, what is the category of an image? Or for instance, to whom should I recommend given product. And based on this data, I would like to generate a program, some sort of the black box or some function that for new examples would be able to give you similar answers. And that's an example of supervised learning. But this is machine learning means that you would like to generate program from data. And this usually uses statistical machine learning methods. So somehow you count somebody, how many times given events occurred or so. Okay, gotcha. And then the third being deep learning. So deep learning, that's one paradigm in terms of machine learning. Okay. And idea behind is ridiculously simple. So people realized that if you want to, as I said, machine learning means that you get data as an input and program as an output. And deep learning says that the computation of the program, what I'm actually doing with this data should involve many steps. Not one step, but many. And pretty much that's it in terms of meaning of deep learning. So you might ask why it's so popular now and how it's so different from what was there before. So it turns out that if you assume that you do one step of computation, let's say that you take your data and you kind of have single if statement or small number of if statements, then like for instance, say if you have a, I don't know, let's say your data is a recording from a stock market and you are saying you're gonna sell or buy depending on value speaker or smaller than something or if if let's say depending or who is the new president or so you are making some decisions so the sense turns out that in case of models that are based on single step people are able to prove plenty of stuff mathematically and in terms of models that require multiple steps of computation, mathematical proofs are extremely weak. And for a long time, models that do single step of computation, they were outperforming models that do many steps of computation. But recently it kind of changed. And for many people, it was obvious for a long time that true intelligence cannot be done in single step, but it would require many steps. But so far, many systems actually worked in the way that they had kind of very shallow, they were very shallow, but simultaneously extremely gigantic. So what I mean by that you could generate let's say for for the task of interest and let's say the recommendation you could generate large number of features let's say thousands of them these are features saying for instance from let's say you want to do movie recommendation. You can say, is movie longer or shorter than two hours? Is it longer or shorter than one hour? There are two features. You can say, is it drama? Is it thriller? Is it something? And you can generate a million of these. And then, or let's say 100, 100 000 that's actually quite reasonable value and then your shallow classifier can essentially determine based on the combination of these features either to recommend it to you or not okay in case of deep learning, you would say, let's kind of combine it for multiple steps. And that's essentially, that's entire difference. And in case of deep learning, the most successful embodiment of deep learning is in terms of neural networks. Okay, so let's define that too. So neural networks, it's also extremely simple concept. And that's something that people came up with a long time ago. And it means as follows. You have an input, this might be say vector or it might have some additional structure like let's say image so it's kind of a matrix two-dimensional and neural network it's a sequence of layers. Layers are represented by matrices. And what you do is you multiply your input by a matrix and apply some nonlinear operation and multiply it again by a matrix and apply nonlinear operation. You might ask, why would I even need to apply this nonlinear operation? Turns out that if you would multiply by two matrices, it can be reduced to multiplication by single matrix. Like a composition of two linear operators can be written as single linear operator. You could multiply these matrices together and the result of the... And you could condense it into single matrix. And non-linearity is something like the classical non-linearity. So, say, there are extremely large number of variants in terms of what I said. But what I just described is so-called feed-forward neural network. So it essentially takes input, multiplies it by matrix, non-linearity multiplies it by matrix. Examples of non-linearities, there is one which is classical, something called sigmoid. So sigmoid is a function that it has a shape of S character, S letter. It's kind of close to zero for negative values. It grows to half at zero and then goes up to one when the values are larger and it kind of modulates the input and that's the most classical version of activation function. It turns out that the one which is even simpler empirically works way better which is called relu rectify linear unit and this one is ridiculously simple relu is just maximum of zero comma x so when you have negative value you set zero you have positive value you just copy the value and that's it so you might ask so first of all what are the successes of deep learning why we actually believe that it works why what change and why it's so much different than it was before and they're like some few different yeah this is a good question no it's exactly much different than it was before. And there are some few differences. This is a good question. No, it's exactly where I was going to go, but I was going to ask beforehand. Yeah, why neural networks are a thing now as opposed to in the past? The main difference is all of a sudden we can train them to solve various problems. And let's say one family of problems, these are problems in supervised learning. So better than any other method, they can map these examples to labels and then on the holdout data, on test data, they outperform anything else. And in many cases, they get superhuman results. And is that just a function of computational power that we have access to? When it comes to models, and neural networks is an example of model, there is always a question, so how to figure out parameters of a model? So there is some training procedure, and the most common procedure for neural networks is so-called stochastic gradient descent. It's also a ridiculously simple procedure. And turns out that empirically it works very well. So people came out with a vast number of learning algorithms. Stochastic gradient descent is an example of one learning algorithm. Others, let's say there is something called Hebbian learning that's motivated by the way how neurons in human brain learn. But this one, so far, empirically, is working the best. Okay. So then let's go to the question you asked yourself, which is why now? What's happening to make people care about it right now? So, so since 20 years ago, there were several small differences in terms of how people train neural networks. And there is a large increase in computational power. So I can speak about the major advances. So number one advance, I would say that's even, the one advance that's actually an old one, but it seems to be extremely critical, something called convolutional neural network. Okay. And what does that mean? Yeah, so it's actually a very simple concept. So let's say your input is an image. And let's say your image is of a size 200 by 200. It has also, let's say three colors so that would the number of values in total is actually 120,000 so if you would actually squash it into a vector this vector would be of this size and then I can think that if you would like, let's say, to apply neural network to essentially multiply it by a matrix, and let's say, if you would like to have output of the multiplication of similar size, let's say 120,000, then all the sudden the matrix to multiply it would be of a gigantic size. And learning consists of estimating parameters of a neural network. It turns out that empirically that wouldn't essentially work. That if you would use algorithm of backpropagation, you would get quite poor results and people realized that in case of images you might want to multiply by a little bit special matrix that also allows to do way faster computation so. So you can think that neural network, as it applies some computation to the input, so neural network applies some computation to the input, you might want to constrain this computation in some sense. So you might think as you will have several layers, maybe initially you would like to do very local computation and it should be pretty much similar in every location. So you would like to apply the same computation in the center as in the corners, maybe later on you need some diversification, but you want to pre-process image the same way. So the idea is that when you take an image or any actually two-dimensional structure, so the other example is you can take voice and it turns out that you can, by applying Fourier transform, you turn voice into image and all the, it's like a two-dimensional image. So like a waveform? Yeah waveform it's a yeah so you take a waveform yeah and you apply for your transform okay and essentially on the x-axis you have time as the speech goes on and on y-axis you have different frequencies and that that's an image and speech recognition systems they also they they treat sound as it would be an image i didn't realize that that's really cool okay so so that's why i'm saying that the the technique that like also like a kind of as a sidetrack, the cool thing about neural networks is it used to be the case that people specialized in processing text, images, sound, and these days this is the same group of people. That's really cool. We are using the same method. So coming back to what is convolutional neural network, as I mentioned, you would like to apply the same computation all over the placing image. And essentially, convolutional neural network says, when we take an image, let's just connect neuron with local values on the image, and let's copy the same weights in the matrix. Okay. So input to the convolution is an image, and output is kind of also an image. You can think that there is also some specific vocabulary. So this kind of three-dimensional image is like you have height and you have also depth. So let's say in case of image, that's three dimensions and then you apply convolution, you can kind of change number of depth dimensions. Usually people go to, let's say, I don't know, know 100 dimensions or so okay gotcha and then you kind of have several of these layers and then there are so-called fully connected layers which are just conventional matrices so i would say that's one of advances that actually happened 20 years ago already another one which is it might sound kind of funny but for a long time people didn't believe that it's possible to train deep neural networks okay and they were they were thinking quite a lot about what what are the proper learning algorithms and it turns out that what are the proper learning algorithms. And it turns out that... So let's say when you train a neural network, you start off by initializing weights to some random values. And it turns out that it's very important to be careful to what magnitudes you initialize weights. And if you set it to right values, and I can even give you some, let's say, intuition of what it means, turns out that then simplest algorithm, which is called stochastic gradient descent, actually works pretty well. Okay. So, in some sense, as I said, let's say, layers of neural network they kind of multiply they multiply input by matrices and a property that you would like to retain you don't want the magnitude of values to blow up and also you don't want it to shrink down and if you choose random initialization, it's easy to just some initialization that will kind of, you know, turn the, the, the, the magnitude to go keep on increasing. And then if you have 10 layers and let's say in each of them, you multiply by two, two, two, two, two, and then the output all the sudden is of completely different completely different magnitude, and learning is not happening anymore. And if you kind of just choose them, and it's a matter of choosing variance, or like a magnitude of initial weights. And if you set it such that, let's say, output is of the same magnitude as input, then everything works. So basically just adjusting those magnitudes was what proved that you could do this with a neural network? Yes. Oh, wow. magnitude as input and everything works. So basically just adjusting those magnitudes was what proved that you could do this with a neural network? Yes. Oh wow, okay. That's kind of ridiculous that let's say people haven't realized it for a long time, but that's what it is. And when and where did that happen? It happened actually at the University of Toronto. Oh, okay. So then at the Jeffries Hinton Lab. So the crazy thing is people had several schemes in terms of how to train deep neural networks. And one was called generative pre-training. And so let's say there was some scheme what to do in order to get to such a state of neural network that all of a sudden you can use this trivial algorithm called stochastic gradient descent so there was like a entire involved procedure and at some point jeffrey asked his student to you know compare it to like the simplest solution which would be adjusting magnitudes and like showing how big difference there is that's crazy man oh my god okay so a question that's a little bit broader is just like then what has happened in the past say five years to excite people so much about AI? So I would say the most stunning were so-called ImageNet results. So first of all, I should tell you where was computer vision five years ago. Then I will tell you what is ImageNet. And then I will tell you what is ImageNet, and then I will tell you about the results. So, computer vision is a field where essentially you try to make sense of images, like a computer tries to interpret what is on images, and it's extremely simple to say, oh, here on an image, there is a cow, a horse or so. But for computer images, just the collection of numbers. So it's a large matrix of numbers. And it's very difficult to say, oh, like how to, it's very difficult to interpret what's the content. And it was the case that people came out with various schemes how to do it you know you could imagine i don't know maybe let's quantify how much of a brown color there is such that you can say it's a horse like a simple stuff but yeah people of course came out with more clever solutions, but the systems were quite bad. I mean, you could feed the picture of a sky to a system and it was telling you that there is a car. So not so good. Yeah. So then Fei-Fei Li, Fei-Fei Li is a professor at Stanford. She, together with her students, she collected the large data set of images and data set is called ImageNet. It consists of one million images and 1,000 classes. So that was, by the time, actually the largest data set of images. And a class, just to clarify, being like car might be a class? Yes. So the data set, I would say it's not perfect. For instance, it doesn't contain people. That was one of of constraints over there it contains large number of breeds of dogs so that's the that's the quirky thing about it but same time i mean that's the essential data set that made deep learning happen types of dogs um No, no. The fact that it's so large. So, so what happened, there was like a plenty of teams actually participating in the immersion competition and, and, and, um, let's say even, as I'm saying, there is 1000 classes over there. So if you have a guess, a random guess, then probability that your guess is correct is essentially 0.1%. The metric there was slightly different. You actually, if you make five guesses and if one of them is correct, then you are good. Okay. Because there might be some other objects and so on. And I remember when I, for the first time, when I have seen that someone made, you know, that someone created a system that had 50% error, I was impressed, okay? I was like, oh man, it's like 1,000 classes and it can say, okay, with 50% error what is there, I was quite impressed. But then during competition, like pretty much like all the teams got around 25% error rate. There was a difference by one person. They're like, for instance, a team from University of Amsterdam, Japanese team, like plenty of people around the world and a team from University of Toronto led by Jeffrey Hinton. And that's like on team was Alex Krzyzewski and Ilya Suskaver. They actually got to something like 15%. So let's say all other teams, they were like a 25%. The difference was 1%. And these two guys, they got to 15%. And the crazy thing is that within following three years on this data set, the error dropped dramatically. I remember like next year the error got to let's say 11%, 8%. I was kind of... I remember by that time I was wondering what's the limit, how good can you be? And I was thinking 5%, that's the best. And even was thinking 5%, that's the best. And even humans trying to see how far they can get if they spend an arbitrary amount of time on, let's say, looking on other images and kind of comparing to be able to figure out what is there. I mean, it's not that simple for humans. For instance, if you have plenty of breeds of dogs and like, who knows, but let's say if you can use some external images to kind of compare and so on, that helps. But in a sense, within several years, people got down, I believe, to 3% error, and that's essentially superhuman performance. And as I'm saying, it used to be the case that systems in computer vision, you take a picture of a sky, they were telling you it's a car, and all of a sudden you are getting to superhuman performance, and it turns out that these results actually are not just limited to computer vision that people were able to get amazing other systems let's say speed recognition or so because that's like the underlying question right because like it's not i mean to someone not in the field like me it's not necessarily intuitive that computer vision, computer image recognition would, you know, seed artificial intelligence. So, I mean, like what came after that? So in a sense, the crazy thing is that the same architectures worked for various tasks. Yeah. Word for various tasks. And all of a sudden, that fields which seem to be unrelated, they started to benefit from each other. So as I mentioned, it turns out that problems in speech recognition can be in a very similar way. You can essentially take speech, apply Fourier transform, and then speech starts to look like an image. And you apply similar object recognition network to kind of recognize what are the sounds over there. And like a phonemes. And so phonemes are like kinds of sounds, and then you can turn it into text. And so that's where it went. So it went to speech after images, and then, yeah. Then the next big thing was essentially translation. Translation was extremely surprising to people. That's the result by Iliassu's cover. was extremely surprising to people. That's the result by Iliasus cover. So translation is an example of another field that actually lived there by its own. And one of the crazy things about translation is input is of a variable length and output is of variable length. And it was unclear even how to kind of consume it with neural network, how to produce variable length input, variable length output. And Ildia came out with an idea. There is something called recurrent neural network. So I mean, let's say recurrent neural network and convolutional neural network, they share an idea, which is you might want to use the same parameters if you are doing similar stuff. And in case of convolutional network, it means let's share the same parameters in space, so let's say let's apply the same transformation to the middle of image as in the corners and so on. And in case of recurrent neural network, as we'll be reading text from left to right, I can consume first word, can create some hidden state representation and then then Then next time step when I'm consuming next word I can take it together with this hidden Representation and generate next hidden representation and you are applying the same function over again and this function Consumes hidden representation and next word hidden representation and the word hidden representation in the word. So it's It's relatively simple. The cool thing is if you are doing it this way Regardless of length of your input you have the same size of a network and The way how his model works, and that's described in a paper called Sequence to Sequence, essentially consume word-by-word sentence that you want to translate. And then when you are about to generate translation, you essentially start emitting word by word. And at the end, when you emit a dot, that's end. That's so cool. And it was quite surprising to people by that time they got to decent performance. They were not able to beat phrase based systems. And now it's like outperform, like a long time ago already. And yeah. The one other issue that people have, so with neural network systems, like in case of translation, the problem with deploying it on the large scale is that it's quite computationally expensive and it requires essentially and in deep learning literature there are various ideas how to make things way way cheaper computationally after you train it so it's possible to throw away a large number of weights or essentially turn floats, 32-bit floats into smaller size numerics and so on and so forth. And pretty much that's the reason why things are not largely deployed in production systems out there. But neural network-based solutions are actually outperforming anything what is out there. There are a couple more things I would like to just define for a general listener. So there are a couple words being thrown around a lot. So narrow AI, general AI, and then superintelligence. Can you just break those apart? Sure. So pretty much all AI that we have out there is narrow AI. No one built so far general AI. No one built super intelligence. So narrow AI means artificial intelligence. So it's like a piece of software that solves a single predefined problem. General AI means it's a piece of software that can solve huge, vast number of problems, all the problems. So you can say that human is general, it's generally intelligent because you can give an arbitrary problem and human can solve it. Okay. But for instance, battle opener can solve only battle opening. Right. So pretty much when we look at any tools out there, at any software, our software is good in solving single problem. For instance, our chess playing programs cannot drive a car. And for any problem, we have to create a separate piece of software. And general artificial intelligence is a software that could solve arbitrary problems. So how we know that is even doable? Because there is an example of a creature that has such a property. And then superintelligence is just, I assume just the next step yeah essentially super intelligence means that it's more intelligent than human um yeah cool so given all that given that like we're basically at a state of narrow ai across the board at this point um where where do you think is like what's the current status of this stuff um where do you see it going in the next five or so years? So as I mentioned, they're essentially machine learning. They're also paradigms. So one of them is supervised learning. There is something called unsupervised learning. There is also something called reinforcement learning. supervised learning, there is also something called reinforcement learning. And so far the supervised learning paradigm is the only one that works so remarkably well that it's ready to be applied in business applications. All others are not really there. And so you ask me where we are. So we can solve this problem, other problems, they require further work. It's very difficult to plan with ideas how long it will take to make them work. The thing which is very different with contemporary artificial intelligence is that we are using precisely the same techniques across the board. Simultaneously, majority of business problems can be framed as supervised learning and therefore they can be solved with current techniques as long as we have sufficient number of input examples and what we want to predict and as i mentioned the pairs can be extremely rich like output might be a sentence and current systems work pretty well with it and nonetheless it requires an expert to train it yeah and so then given the um given like pretty substantial hype we see um what do you think of it all? The field is simultaneously underhyped and overhyped. So from perspective of business application, as long as you have pairs of examples, pairs from like that indicate mapping, like what's the input, what's the output, we can pretty often get to superhuman performance. But in all other fields, we are still not there. And it's unclear how long it will take. So I'll give some example. Let's say for recommendation systems, you have often companies like Amazon, they have examples of millions of users and they know what they bought when they were happy or not. And that's an example of a task that is pretty good for neural network to learn what to recommend to new users. learn what to recommend to new users. Simultaneously, Google knows what is the good search query for you because on the search result page we are clicking on the links that you are interested in and therefore they should be displayed first. And in other fields it's actually quite often more difficult like in case of let's say apple picking robot it's difficult to provide supervised data telling how to move an arm toward apple therefore that's way more complicated same, the problem of detecting where Apple is, it's where better defined and can be outsourced to human to annotate plenty of images and to give localization of the Apple. And quite often the rest of the problem can be scripted by engineer. But the problem of how to place fingers on an apple or how to grip it, it's not well scientifically solved. And so we have a couple questions then at this point. If people were to be interested in learning more about AI and maybe working with OpenAI or doing something, how would you recommend they get involved and educate themselves? So I'd say a good place to start is Coursera. Coursera is pretty good. There is also a lot of TensorFlow tutorials. TensorFlow is an example of a framework to train neural networks. Okay. Also, Andre Carpati's class at Stanford. It's extremely accessible. You can find it on i believe on youtube yeah and then like in terms of um actual exercises so um in case of tensorflow tutorial um many of the problems uh so so i believe in case of andrei's class, there might be homework. And in case of TensorFlow exercises, it's quite often easy to come up with some random thought after, let's say, reading. I mean, you can take, for instance, let's say, the simple task over there is let's classify digits and let's classify pictures of digits. Let's assign them classes. You can try maybe download some images from some other source, like a Flickr. Let's try to classify it toward tags. Okay, so given that you guys are working with robots at this point, one of the other things that's thrown in kind of part and parcel with AI is automation, specifically of a lot of these low-level blue-collar jobs. What do you think about the future, maybe the next 10 years of those jobs? So I believe that we'll have to offer to people basic income. I super strongly believe that actually that's the only way. So I don't think that it will be possible for 40 years old taxi driver to reinvent himself every 10 years. I think it might be another big social problem simultaneously they might not even like their jobs like if you ask someone would you like your kid to sell in a supermarket, to be a seller in a supermarket, they would answer no. And maybe it's possible to live in a world that there is abundance of resources and people can just enjoy their life. I think we're going to have to figure out a way. I mean, maybe people will always find purpose, but I think making it easier to find that purpose will become much more important in the future if automation actually happens to the degree people talk about. And what about just influences on you that maybe have inspired you to work with robotics and in AI? Are there any like books or films or any media that you really enjoyed? There is pretty good book called Homo Deus. It actually describes the history of humans and then speaks, then has various predictions about the future or where we are heading that's one pretty good mm-hmm I mean there is nowadays there is like a plenty of movies about AI and how it can go wrong. What's the best one? I think Hair is pretty good. Okay. Yeah, Ex Machina is also pretty good. Cool. All right, do you have any other last things you want to address? Oh, I think not. No, thank you. Okay, cool. Thanks, man.